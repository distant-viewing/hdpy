<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Taylor Arnold and Lauren Tilton">

<title>10&nbsp; Image Data – Humanities Data in Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./11_audio_data.html" rel="next">
<link href="./09_spatial_data.html" rel="prev">
<link href="./owl_explore.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7dd7401653f9b7f7a674e3bd3661a20e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_textual_data.html">Part II: Data Types</a></li><li class="breadcrumb-item"><a href="./10_image_data.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Image Data</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Humanities Data in Python</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/distant-viewing/hdpy" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Core</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_graphics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">EDA I: Visualizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_verbs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">EDA II: Organizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_combine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">EDA III: Restructuring Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_collect.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Collecting Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Data Types</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_textual_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Textual Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_network_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Network Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_temporal_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Temporal Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_spatial_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_image_data.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Image Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_audio_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Audio Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_movingimage_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Moving Image Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_supervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Supervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_unsupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Unsupervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_deeplearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Transformers</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part IV: Programming</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_program.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_jsonxml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">JSON + XML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_databases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Databases</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">10.1</span> Introduction</a></li>
  <li><a href="#loading-images" id="toc-loading-images" class="nav-link" data-scroll-target="#loading-images"><span class="header-section-number">10.2</span> Loading Images</a></li>
  <li><a href="#pixels-and-color" id="toc-pixels-and-color" class="nav-link" data-scroll-target="#pixels-and-color"><span class="header-section-number">10.3</span> Pixels and Color</a></li>
  <li><a href="#computer-vision-with-opencv" id="toc-computer-vision-with-opencv" class="nav-link" data-scroll-target="#computer-vision-with-opencv"><span class="header-section-number">10.4</span> Computer Vision with OpenCV</a></li>
  <li><a href="#embeddings-and-similarity" id="toc-embeddings-and-similarity" class="nav-link" data-scroll-target="#embeddings-and-similarity"><span class="header-section-number">10.5</span> Embeddings and Similarity</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions"><span class="header-section-number">10.6</span> Extensions</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_textual_data.html">Part II: Data Types</a></li><li class="breadcrumb-item"><a href="./10_image_data.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Image Data</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ch10" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Image Data</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">10.1</span> Introduction</h2>
<p>A large amount of humanities data consists of digitized image data, and there is an active push to digitize even more. Examples of large corpora include Google Books, HathiTrust, U.S. Library of Congress, the Getty Museum, Europeana, Wikimedia, and the Rijksmuseum. In some cases, these image collections represent scans of mostly textual data. In others, the images represent digitized art works or photographic prints; in these cases the images serve as direct historical evidence, objects of study in their own right, or both. Converting images with text into raw text data is an interesting problem in computer vision, known as <em>optical character recognition</em> or OCR. However, we will concentrate in this chapter only on the cases where images directly represent artwork and historical documents that are known for their visual semantics.</p>
<p>While many humanities projects have worked with image data over the years, it has only been recently that there has been a large push to analyze the actual images themselves. Our own work has theorized and offered a method for computationally working with digital images called Distant Viewing, which we expand on in an open access book by the same name <span class="citation" data-cites="arnold2023distant">[<a href="#ref-arnold2023distant" role="doc-biblioref">1</a>]</span>. Others have offered concepts such as deep watching and cultural analytics <span class="citation" data-cites="bermeitinger2019deep">[<a href="#ref-bermeitinger2019deep" role="doc-biblioref">2</a>]</span> <span class="citation" data-cites="manovich2020cultural">[<a href="#ref-manovich2020cultural" role="doc-biblioref">3</a>]</span>. All are concerned with how to computationally analyze images for there are many possibilities from fields such as art history, film and media studies, visual culture studies and more.</p>
</section>
<section id="loading-images" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="loading-images"><span class="header-section-number">10.2</span> Loading Images</h2>
<p>We will be working with a new dataset in this chapter. Our collection consists of the images taken by the photographic unit of the United States Farm Securities Administration and Office of War Information, commonly called the FSA-OWI. While best known for the over 170 thousand black-and-white images documenting the United States during the Great Depression and World War II, the FSA-OWI also created over sixteen hundred color photographs. Both of these collections are ones that we have worked extensively with in a variety of projects. The color subset is a perfect size to demonstrate the methods in this chapter and, unlike the black-and-white images, will allow us to start with a study of several color-based analyses.</p>
<p>Our analysis of image data in Python will in many ways follow the pattern seen in the previous chapters. We work to organize our data into structured, tabular datasets that capture information and models about the data. Then, we use the visualization and manipulation approaches in the first five chapters to understand the information in each table. To start, we will load a CSV file into Python that contains metadata about each of the images:</p>
<div id="07a9acce" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>fsac <span class="op">=</span> pd.read_csv(<span class="st">"data/fsac_metadata.csv.bz2"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>fsac.sample(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">filename</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">height</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">thm_path</th>
<th data-quarto-table-cell-role="th">med_path</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1304</td>
<td>2017878545</td>
<td>1939</td>
<td>Two women workers are shown capping and inspec...</td>
<td>828</td>
<td>1024</td>
<td>data/fsac/thm/2017878545.jpg</td>
<td>data/fsac/med/2017878545.jpg</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>2017877459</td>
<td>1939</td>
<td>Planting corn along a river in Tennessee</td>
<td>1024</td>
<td>726</td>
<td>data/fsac/thm/2017877459.jpg</td>
<td>data/fsac/med/2017877459.jpg</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">906</td>
<td>2017877475</td>
<td>1939</td>
<td>Natchez, Miss.</td>
<td>1024</td>
<td>725</td>
<td>data/fsac/thm/2017877475.jpg</td>
<td>data/fsac/med/2017877475.jpg</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">203</td>
<td>2017878788</td>
<td>1939</td>
<td>Hanna furnaces of the Great Lakes Steel Corpor...</td>
<td>811</td>
<td>1024</td>
<td>data/fsac/thm/2017878788.jpg</td>
<td>data/fsac/med/2017878788.jpg</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">245</td>
<td>2017878798</td>
<td>1939</td>
<td>Bands of sheep [i.e. cattle] on the Gravelly R...</td>
<td>804</td>
<td>1024</td>
<td>data/fsac/thm/2017878798.jpg</td>
<td>data/fsac/med/2017878798.jpg</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">580</td>
<td>2017877760</td>
<td>1939</td>
<td>FSA - T[enant] P[urchase] borrower? by his fie...</td>
<td>721</td>
<td>1024</td>
<td>data/fsac/thm/2017877760.jpg</td>
<td>data/fsac/med/2017877760.jpg</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">683</td>
<td>2017877799</td>
<td>1939</td>
<td>Sugar cane land, vicinity of Rio Piedras, Puer...</td>
<td>1024</td>
<td>729</td>
<td>data/fsac/thm/2017877799.jpg</td>
<td>data/fsac/med/2017877799.jpg</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">820</td>
<td>2017877519</td>
<td>1939</td>
<td>Chopping cotton on rented land near White Plai...</td>
<td>792</td>
<td>1024</td>
<td>data/fsac/thm/2017877519.jpg</td>
<td>data/fsac/med/2017877519.jpg</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">436</td>
<td>2017877612</td>
<td>1939</td>
<td>Winner at the Delta County Fair, Colorado</td>
<td>1024</td>
<td>703</td>
<td>data/fsac/thm/2017877612.jpg</td>
<td>data/fsac/med/2017877612.jpg</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">627</td>
<td>2017878942</td>
<td>1939</td>
<td>Cultivating sugar cane on the Virgin Islands C...</td>
<td>710</td>
<td>1024</td>
<td>data/fsac/thm/2017878942.jpg</td>
<td>data/fsac/med/2017878942.jpg</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The metadata includes a unique identifier for each image in the first column. It also contains the year in which the photograph was taken and a short title of the photograph. This table also has the dimensions of the image and columns that have the file path to two versions of each image. One copy is a small thumbnail that will be useful to efficiently create visualizations. The other image is the larger version that we will use for most of the actual analyses. Unlike other data types that we have seen, image data is usually stored as a set of separate files, with one file storing the information about a single image. It is not necessary when working with an image collection to have two versions of each image, but if we are given them, as is this case with this collection, it can be helpful to keep both to speed up the visualization techniques.</p>
<p>Our work with images in this chapter will use several powerful Python libraries. <strong>PIL (Python Imaging Library)</strong> and <strong>OpenCV</strong> will handle image loading and basic processing. <strong>scikit-image</strong> provides additional image processing capabilities. For computer vision tasks, we’ll use <strong>OpenCV</strong> and potentially <strong>MediaPipe</strong> for more advanced features. <strong>matplotlib</strong> will handle visualization, and we’ll use <strong>numpy</strong> extensively for array operations since images are represented as numerical arrays.</p>
<div id="bc112be8" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage <span class="im">import</span> color</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As a starting point, we will read a single image into Python and see how it is represented. Python’s PIL library makes this straightforward:</p>
<div id="14580d4d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the first image</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> fsac[<span class="st">'thm_path'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load with PIL</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>img_pil <span class="op">=</span> Image.<span class="bu">open</span>(image_path)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PIL Image size: </span><span class="sc">{</span>img_pil<span class="sc">.</span>size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PIL Image mode: </span><span class="sc">{</span>img_pil<span class="sc">.</span>mode<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to numpy array for analysis</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> np.array(img_pil)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Array shape: </span><span class="sc">{</span>img_array<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Array data type: </span><span class="sc">{</span>img_array<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>PIL Image size: (150, 105)
PIL Image mode: RGB
Array shape: (105, 150, 3)
Array data type: uint8</code></pre>
</div>
</div>
<p>Image data is represented as one or more rectangular grids of pixels, the smallest identifiable locations of an image. A pixel is defined by a set of three numbers giving the intensity of the red, green, and blue lights needed to represent the color of that part of the image on a digital display. The array that we now have in Python represents our image in pixels. We can see that the thumbnail has dimensions corresponding to height, width, and the usual three color channels for red, green, and blue intensities. Let’s examine the pixel values:</p>
<div id="a27900e0" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(img_array[:<span class="dv">4</span>, :<span class="dv">4</span>, :])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Pixel value range: </span><span class="sc">{</span>img_array<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>img_array<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[[31 51  0]
  [36 56  5]
  [37 56 10]
  [25 43  1]]

 [[37 57  6]
  [20 40  0]
  [32 51  6]
  [44 62 22]]

 [[36 55  9]
  [45 64 19]
  [42 58 19]
  [33 49 13]]

 [[34 52 10]
  [31 49  9]
  [34 50 14]
  [36 51 20]]]

Pixel value range: 0 to 255</code></pre>
</div>
</div>
<p>We see that each pixel intensity is given as a number between 0 and 255 for uint8 images (the most common format). A value of 255 indicates maximum intensity, while 0 indicates no intensity for that color channel.</p>
<p>Working directly with the array format gives us full control, but for analysis it’s often useful to convert to a tabular format with one row per pixel:</p>
<div id="d0e03515" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_to_dataframe(image_path, image_id<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Convert an image to a DataFrame with one row per pixel."""</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load image</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(image_path)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    img_array <span class="op">=</span> np.array(img)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get dimensions</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    height, width <span class="op">=</span> img_array.shape[:<span class="dv">2</span>]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle grayscale vs color images</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(img_array.shape) <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        channels <span class="op">=</span> img_array.shape[<span class="dv">2</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        channels <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> img_array[:, :, np.newaxis]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create coordinate grids</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    rows, cols <span class="op">=</span> np.mgrid[<span class="dv">0</span>:height, <span class="dv">0</span>:width]</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten everything</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    pixel_data <span class="op">=</span> {</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'image_id'</span>: image_id <span class="kw">or</span> <span class="dv">0</span>,</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'row'</span>: rows.flatten(),</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'col'</span>: cols.flatten(),</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'height'</span>: height,</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'width'</span>: width</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add color channels</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> channels <span class="op">&gt;=</span> <span class="dv">3</span>:</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'red'</span>] <span class="op">=</span> img_array[:, :, <span class="dv">0</span>].flatten()</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'green'</span>] <span class="op">=</span> img_array[:, :, <span class="dv">1</span>].flatten()</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'blue'</span>] <span class="op">=</span> img_array[:, :, <span class="dv">2</span>].flatten()</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert RGB to HSV for analysis</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        img_hsv <span class="op">=</span> color.rgb2hsv(img_array <span class="op">/</span> <span class="fl">255.0</span>)  <span class="co"># Convert to 0-1 range for HSV</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'hue'</span>] <span class="op">=</span> img_hsv[:, :, <span class="dv">0</span>].flatten()</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'saturation'</span>] <span class="op">=</span> img_hsv[:, :, <span class="dv">1</span>].flatten()</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'value'</span>] <span class="op">=</span> img_hsv[:, :, <span class="dv">2</span>].flatten()</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create hex color representation</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        hex_colors <span class="op">=</span> []</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> r, g, b <span class="kw">in</span> <span class="bu">zip</span>(pixel_data[<span class="st">'red'</span>], pixel_data[<span class="st">'green'</span>], pixel_data[<span class="st">'blue'</span>]):</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>            hex_colors.append(<span class="ss">f'#</span><span class="sc">{</span>r<span class="sc">:02x}{</span>g<span class="sc">:02x}{</span>b<span class="sc">:02x}</span><span class="ss">'</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        pixel_data[<span class="st">'hex'</span>] <span class="op">=</span> hex_colors</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(pixel_data)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert our first image to DataFrame format</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>pix_single <span class="op">=</span> image_to_dataframe(fsac[<span class="st">'thm_path'</span>].iloc[<span class="dv">0</span>], fsac[<span class="st">'filename'</span>].iloc[<span class="dv">0</span>])</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>pix_single</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">image_id</th>
<th data-quarto-table-cell-role="th">row</th>
<th data-quarto-table-cell-role="th">col</th>
<th data-quarto-table-cell-role="th">height</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">red</th>
<th data-quarto-table-cell-role="th">green</th>
<th data-quarto-table-cell-role="th">blue</th>
<th data-quarto-table-cell-role="th">hue</th>
<th data-quarto-table-cell-role="th">saturation</th>
<th data-quarto-table-cell-role="th">value</th>
<th data-quarto-table-cell-role="th">hex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877351</td>
<td>0</td>
<td>0</td>
<td>105</td>
<td>150</td>
<td>31</td>
<td>51</td>
<td>0</td>
<td>0.232026</td>
<td>1.000000</td>
<td>0.200000</td>
<td>#1f3300</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877351</td>
<td>0</td>
<td>1</td>
<td>105</td>
<td>150</td>
<td>36</td>
<td>56</td>
<td>5</td>
<td>0.232026</td>
<td>0.910714</td>
<td>0.219608</td>
<td>#243805</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2017877351</td>
<td>0</td>
<td>2</td>
<td>105</td>
<td>150</td>
<td>37</td>
<td>56</td>
<td>10</td>
<td>0.235507</td>
<td>0.821429</td>
<td>0.219608</td>
<td>#25380a</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2017877351</td>
<td>0</td>
<td>3</td>
<td>105</td>
<td>150</td>
<td>25</td>
<td>43</td>
<td>1</td>
<td>0.238095</td>
<td>0.976744</td>
<td>0.168627</td>
<td>#192b01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2017877351</td>
<td>0</td>
<td>4</td>
<td>105</td>
<td>150</td>
<td>38</td>
<td>56</td>
<td>16</td>
<td>0.241667</td>
<td>0.714286</td>
<td>0.219608</td>
<td>#263810</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15745</td>
<td>2017877351</td>
<td>104</td>
<td>145</td>
<td>105</td>
<td>150</td>
<td>30</td>
<td>44</td>
<td>8</td>
<td>0.231481</td>
<td>0.818182</td>
<td>0.172549</td>
<td>#1e2c08</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15746</td>
<td>2017877351</td>
<td>104</td>
<td>146</td>
<td>105</td>
<td>150</td>
<td>29</td>
<td>43</td>
<td>7</td>
<td>0.231481</td>
<td>0.837209</td>
<td>0.168627</td>
<td>#1d2b07</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15747</td>
<td>2017877351</td>
<td>104</td>
<td>147</td>
<td>105</td>
<td>150</td>
<td>32</td>
<td>46</td>
<td>10</td>
<td>0.231481</td>
<td>0.782609</td>
<td>0.180392</td>
<td>#202e0a</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15748</td>
<td>2017877351</td>
<td>104</td>
<td>148</td>
<td>105</td>
<td>150</td>
<td>33</td>
<td>47</td>
<td>11</td>
<td>0.231481</td>
<td>0.765957</td>
<td>0.184314</td>
<td>#212f0b</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15749</td>
<td>2017877351</td>
<td>104</td>
<td>149</td>
<td>105</td>
<td>150</td>
<td>32</td>
<td>46</td>
<td>10</td>
<td>0.231481</td>
<td>0.782609</td>
<td>0.180392</td>
<td>#202e0a</td>
</tr>
</tbody>
</table>

<p>15750 rows × 12 columns</p>
</div>
</div>
</div>
<p>Notice that the output has one row for each pixel. The first column identifies the image, followed by row and column coordinates, image dimensions, and then the RGB color values. We’ve also computed HSV (Hue, Saturation, Value) representations and hex color codes. Four other derived measurements are provided in the last columns. We will investigate these measurements in the next section.</p>
<p>Now let’s create a function to process multiple images:</p>
<div id="622bf0a0" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_image_collection(image_paths, image_ids, max_images<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Process a collection of images into a combined pixel DataFrame."""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> max_images:</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        image_paths <span class="op">=</span> image_paths[:max_images]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        image_ids <span class="op">=</span> image_ids[:max_images]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    pixel_dataframes <span class="op">=</span> []</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (path, img_id) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(image_paths, image_ids)):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>            df <span class="op">=</span> image_to_dataframe(path, img_id)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>            pixel_dataframes.append(df)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Processed </span><span class="sc">{</span>i <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> images..."</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Error processing </span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.concat(pixel_dataframes, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co"># For demonstration, let's process just the first 10 images</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Processing first 10 images..."</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>pix_sample <span class="op">=</span> process_image_collection(</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'thm_path'</span>].iloc[:<span class="dv">10</span>].tolist(),</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'filename'</span>].iloc[:<span class="dv">10</span>].tolist()</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>pix_sample</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing first 10 images...</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">image_id</th>
<th data-quarto-table-cell-role="th">row</th>
<th data-quarto-table-cell-role="th">col</th>
<th data-quarto-table-cell-role="th">height</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">red</th>
<th data-quarto-table-cell-role="th">green</th>
<th data-quarto-table-cell-role="th">blue</th>
<th data-quarto-table-cell-role="th">hue</th>
<th data-quarto-table-cell-role="th">saturation</th>
<th data-quarto-table-cell-role="th">value</th>
<th data-quarto-table-cell-role="th">hex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877351</td>
<td>0</td>
<td>0</td>
<td>105</td>
<td>150</td>
<td>31</td>
<td>51</td>
<td>0</td>
<td>0.232026</td>
<td>1.000000</td>
<td>0.200000</td>
<td>#1f3300</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877351</td>
<td>0</td>
<td>1</td>
<td>105</td>
<td>150</td>
<td>36</td>
<td>56</td>
<td>5</td>
<td>0.232026</td>
<td>0.910714</td>
<td>0.219608</td>
<td>#243805</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2017877351</td>
<td>0</td>
<td>2</td>
<td>105</td>
<td>150</td>
<td>37</td>
<td>56</td>
<td>10</td>
<td>0.235507</td>
<td>0.821429</td>
<td>0.219608</td>
<td>#25380a</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2017877351</td>
<td>0</td>
<td>3</td>
<td>105</td>
<td>150</td>
<td>25</td>
<td>43</td>
<td>1</td>
<td>0.238095</td>
<td>0.976744</td>
<td>0.168627</td>
<td>#192b01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2017877351</td>
<td>0</td>
<td>4</td>
<td>105</td>
<td>150</td>
<td>38</td>
<td>56</td>
<td>16</td>
<td>0.241667</td>
<td>0.714286</td>
<td>0.219608</td>
<td>#263810</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">158845</td>
<td>2017877478</td>
<td>108</td>
<td>145</td>
<td>109</td>
<td>150</td>
<td>51</td>
<td>87</td>
<td>26</td>
<td>0.265027</td>
<td>0.701149</td>
<td>0.341176</td>
<td>#33571a</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">158846</td>
<td>2017877478</td>
<td>108</td>
<td>146</td>
<td>109</td>
<td>150</td>
<td>51</td>
<td>85</td>
<td>24</td>
<td>0.259563</td>
<td>0.717647</td>
<td>0.333333</td>
<td>#335518</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">158847</td>
<td>2017877478</td>
<td>108</td>
<td>147</td>
<td>109</td>
<td>150</td>
<td>51</td>
<td>85</td>
<td>24</td>
<td>0.259563</td>
<td>0.717647</td>
<td>0.333333</td>
<td>#335518</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">158848</td>
<td>2017877478</td>
<td>108</td>
<td>148</td>
<td>109</td>
<td>150</td>
<td>55</td>
<td>87</td>
<td>24</td>
<td>0.251323</td>
<td>0.724138</td>
<td>0.341176</td>
<td>#375718</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">158849</td>
<td>2017877478</td>
<td>108</td>
<td>149</td>
<td>109</td>
<td>150</td>
<td>56</td>
<td>88</td>
<td>25</td>
<td>0.251323</td>
<td>0.715909</td>
<td>0.345098</td>
<td>#385819</td>
</tr>
</tbody>
</table>

<p>158850 rows × 12 columns</p>
</div>
</div>
</div>
</section>
<section id="pixels-and-color" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="pixels-and-color"><span class="header-section-number">10.3</span> Pixels and Color</h2>
<p>Let’s now see if we can use the pixel-level data to do some exploratory data analysis with the images. Since processing all 1,600 images would create an enormous dataset, we’ll work with subsets and demonstrate the techniques that could be scaled up.</p>
<p>It is tempting to use the red, green, and blue pixel intensities directly to compute summary values for the images. For example, we might want to group by filename and determine which images have the highest average values of green. Unfortunately, our current calculations will not actually indicate very clearly which images contain the color that we would perceive as green. The color of a pixel can be represented as three numbers because the human eye has three different kinds of cells, called <em>cones</em>, that are sensitive to three different wavelengths of light.</p>
<p>The blending of colors is what makes it challenging to summarize raw pixel intensities. An image that has a large average green intensity could have a lot of green in it. But, if the green is always blended with red, it could be primarily yellow. Or, if all three intensities are high, the image might only have a large amount of white. In order to work around this issue, it is useful to transform the pixel intensities into a new set of numbers that more closely represent the way that we think about color working. We will work with the HSV representation, which stands for hue, saturation, and value.</p>
<p>The <em>value</em> of a pixel represents how bright or intense the pixel is. The <em>saturation</em> measures the richness of a color, with zero being a shade of grey and one being a “pure” color. The <em>hue</em> corresponds to information about where a pixel sits in the rainbow of colors, roughly corresponding to a color wheel.</p>
<p>Let’s visualize the pixel colors from our sample images:</p>
<div id="bdbcfa34" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create HSV visualization for the first few images</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>sample_images <span class="op">=</span> pix_sample[pix_sample[<span class="st">'image_id'</span>].isin(pix_sample[<span class="st">'image_id'</span>].unique()[:<span class="dv">6</span>])]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> (ggplot(sample_images, aes(x<span class="op">=</span><span class="st">'hue'</span>, y<span class="op">=</span><span class="st">'saturation'</span>)) <span class="op">+</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>     geom_point(aes(color<span class="op">=</span><span class="st">'hex'</span>), alpha<span class="op">=</span><span class="fl">0.6</span>, size<span class="op">=</span><span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>     scale_color_identity() <span class="op">+</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>     facet_wrap(<span class="st">'~image_id'</span>, ncol<span class="op">=</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>     labs(title<span class="op">=</span><span class="st">"Pixel Colors in Sample Images (HSV Space)"</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>          x<span class="op">=</span><span class="st">"Hue"</span>, y<span class="op">=</span><span class="st">"Saturation"</span>) <span class="op">+</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>     theme_minimal())</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="10_image_data_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="10_image_data_files/figure-html/cell-9-output-1.png" width="672" height="480" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Let’s also look at the actual images for reference:</p>
<div id="d0a63c88" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the actual images</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, img_id <span class="kw">in</span> <span class="bu">enumerate</span>(pix_sample[<span class="st">'image_id'</span>].unique()[:<span class="dv">6</span>]):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    img_path <span class="op">=</span> fsac[fsac[<span class="st">'filename'</span>] <span class="op">==</span> img_id][<span class="st">'thm_path'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    axes[i].imshow(img)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f"Image: </span><span class="sc">{</span>img_id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    axes[i].axis(<span class="st">'off'</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="10_image_data_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="10_image_data_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Now we can use the HSV measurements to analyze our image collection. Let’s find the darkest images by computing average brightness (value):</p>
<div id="4c519d81" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute average brightness for each image</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>brightness_summary <span class="op">=</span> (pix_sample</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'image_id'</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    .agg({<span class="st">'value'</span>: <span class="st">'mean'</span>})</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    .reset_index()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">'value'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Join with metadata to see titles</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>dark_images <span class="op">=</span> (brightness_summary</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    .merge(fsac, left_on<span class="op">=</span><span class="st">'image_id'</span>, right_on<span class="op">=</span><span class="st">'filename'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">10</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>dark_images[[<span class="st">'filename'</span>, <span class="st">'title'</span>, <span class="st">'value'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">filename</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877351</td>
<td>Commuters, who have just come off the train, w...</td>
<td>0.200132</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877502</td>
<td>Going to town on Saturday afternoon, Greene Co...</td>
<td>0.320172</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2017877477</td>
<td>Negroes fishing in creek near cotton plantatio...</td>
<td>0.334167</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2017877476</td>
<td>Southern U.S., Mississippi?</td>
<td>0.340388</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2017877453</td>
<td>A train bringing copper ore out of the mine, D...</td>
<td>0.356685</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>2017877451</td>
<td>Copper mining and sulfuric acid plant, Copperh...</td>
<td>0.391784</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>2017877454</td>
<td>Copper mining and sulfuric acid plant, Copperh...</td>
<td>0.410381</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>2017877478</td>
<td>Negroes fishing in creek near cotton plantatio...</td>
<td>0.423666</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>2017877359</td>
<td>Railroad cars and factory buildings in Lawrenc...</td>
<td>0.455252</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>2017877452</td>
<td>Copper mining and sulfuric acid plant, Copperh...</td>
<td>0.462848</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Similarly, we can look at images with highly saturated colors:</p>
<div id="aa903ddd" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find images with saturated colors</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>saturation_summary <span class="op">=</span> (pix_sample</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">'saturation &gt; 0.8 and value &gt; 0.5'</span>)  <span class="co"># Bright and saturated pixels</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'image_id'</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    .size()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    .reset_index(name<span class="op">=</span><span class="st">'saturated_pixel_count'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate proportion of saturated pixels</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>image_totals <span class="op">=</span> (pix_sample</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'image_id'</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    .size()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    .reset_index(name<span class="op">=</span><span class="st">'total_pixels'</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>saturated_analysis <span class="op">=</span> (saturation_summary</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    .merge(image_totals, on<span class="op">=</span><span class="st">'image_id'</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    .assign(saturated_proportion <span class="op">=</span> <span class="kw">lambda</span> df: df[<span class="st">'saturated_pixel_count'</span>] <span class="op">/</span> df[<span class="st">'total_pixels'</span>])</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">'saturated_proportion'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    .merge(fsac, left_on<span class="op">=</span><span class="st">'image_id'</span>, right_on<span class="op">=</span><span class="st">'filename'</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>saturated_analysis[[<span class="st">'filename'</span>, <span class="st">'title'</span>, <span class="st">'saturated_proportion'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">filename</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">saturated_proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877478</td>
<td>Negroes fishing in creek near cotton plantatio...</td>
<td>0.012232</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877476</td>
<td>Southern U.S., Mississippi?</td>
<td>0.000881</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>For hue analysis, we can group similar hues into buckets and analyze color distribution:</p>
<div id="47d9e810" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyze_dominant_hues(pixel_df, n_hue_bins<span class="op">=</span><span class="dv">12</span>):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Analyze dominant hues in images."""</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter to sufficiently bright and saturated pixels</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    filtered_pixels <span class="op">=</span> pixel_df.query(<span class="st">'value &gt; 0.2 and saturation &gt; 0.2'</span>).copy()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create hue bins</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    filtered_pixels[<span class="st">'hue_bin'</span>] <span class="op">=</span> np.floor(filtered_pixels[<span class="st">'hue'</span>] <span class="op">*</span> n_hue_bins).astype(<span class="bu">int</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate proportions for each image and hue bin</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    hue_props <span class="op">=</span> (filtered_pixels</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        .groupby([<span class="st">'image_id'</span>, <span class="st">'hue_bin'</span>])</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        .size()</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        .reset_index(name<span class="op">=</span><span class="st">'pixel_count'</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add total pixels per image for proportion calculation</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    total_pixels <span class="op">=</span> (filtered_pixels</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        .groupby(<span class="st">'image_id'</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        .size()</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        .reset_index(name<span class="op">=</span><span class="st">'total_pixels'</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    hue_analysis <span class="op">=</span> (hue_props</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        .merge(total_pixels, on<span class="op">=</span><span class="st">'image_id'</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        .assign(proportion <span class="op">=</span> <span class="kw">lambda</span> df: df[<span class="st">'pixel_count'</span>] <span class="op">/</span> df[<span class="st">'total_pixels'</span>])</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        .sort_values(<span class="st">'proportion'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hue_analysis</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze hues in our sample</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>hue_results <span class="op">=</span> analyze_dominant_hues(pix_sample)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>hue_results.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">image_id</th>
<th data-quarto-table-cell-role="th">hue_bin</th>
<th data-quarto-table-cell-role="th">pixel_count</th>
<th data-quarto-table-cell-role="th">total_pixels</th>
<th data-quarto-table-cell-role="th">proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">25</td>
<td>2017877454</td>
<td>0</td>
<td>5152</td>
<td>5246</td>
<td>0.982082</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>2017877452</td>
<td>0</td>
<td>6395</td>
<td>6880</td>
<td>0.929506</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">43</td>
<td>2017877478</td>
<td>1</td>
<td>12608</td>
<td>15047</td>
<td>0.837908</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>2017877451</td>
<td>0</td>
<td>4294</td>
<td>5344</td>
<td>0.803518</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>2017877453</td>
<td>0</td>
<td>6672</td>
<td>8505</td>
<td>0.784480</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">12</td>
<td>2017877359</td>
<td>7</td>
<td>6255</td>
<td>9508</td>
<td>0.657867</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">39</td>
<td>2017877477</td>
<td>1</td>
<td>6147</td>
<td>10608</td>
<td>0.579468</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877351</td>
<td>1</td>
<td>527</td>
<td>955</td>
<td>0.551832</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">29</td>
<td>2017877476</td>
<td>1</td>
<td>3445</td>
<td>7920</td>
<td>0.434975</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">38</td>
<td>2017877477</td>
<td>0</td>
<td>4435</td>
<td>10608</td>
<td>0.418081</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Let’s create a more comprehensive analysis with a larger sample:</p>
<div id="87bbb163" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Process more images for better analysis (first 50 to keep manageable)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Processing first 50 images for comprehensive analysis..."</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>pix_extended <span class="op">=</span> process_image_collection(</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'thm_path'</span>].iloc[:<span class="dv">50</span>].tolist(),</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'filename'</span>].iloc[:<span class="dv">50</span>].tolist()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze color characteristics</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>color_summary <span class="op">=</span> (pix_extended</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'image_id'</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    .agg({</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'value'</span>: [<span class="st">'mean'</span>, <span class="st">'std'</span>],</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'saturation'</span>: [<span class="st">'mean'</span>, <span class="st">'std'</span>], </span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'hue'</span>: [<span class="st">'mean'</span>, <span class="st">'std'</span>]</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten column names</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>color_summary.columns <span class="op">=</span> [<span class="st">'_'</span>.join(col).strip() <span class="cf">for</span> col <span class="kw">in</span> color_summary.columns]</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>color_summary <span class="op">=</span> color_summary.reset_index()</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>color_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing first 50 images for comprehensive analysis...</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">image_id</th>
<th data-quarto-table-cell-role="th">value_mean</th>
<th data-quarto-table-cell-role="th">value_std</th>
<th data-quarto-table-cell-role="th">saturation_mean</th>
<th data-quarto-table-cell-role="th">saturation_std</th>
<th data-quarto-table-cell-role="th">hue_mean</th>
<th data-quarto-table-cell-role="th">hue_std</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877342</td>
<td>0.204</td>
<td>0.088</td>
<td>0.362</td>
<td>0.108</td>
<td>0.097</td>
<td>0.096</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877343</td>
<td>0.443</td>
<td>0.296</td>
<td>0.409</td>
<td>0.241</td>
<td>0.245</td>
<td>0.326</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2017877344</td>
<td>0.409</td>
<td>0.115</td>
<td>0.434</td>
<td>0.146</td>
<td>0.231</td>
<td>0.133</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2017877345</td>
<td>0.432</td>
<td>0.213</td>
<td>0.434</td>
<td>0.230</td>
<td>0.234</td>
<td>0.296</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2017877346</td>
<td>0.454</td>
<td>0.233</td>
<td>0.343</td>
<td>0.128</td>
<td>0.483</td>
<td>0.235</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>2017877347</td>
<td>0.428</td>
<td>0.221</td>
<td>0.312</td>
<td>0.136</td>
<td>0.347</td>
<td>0.253</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>2017877348</td>
<td>0.356</td>
<td>0.174</td>
<td>0.424</td>
<td>0.284</td>
<td>0.209</td>
<td>0.221</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>2017877349</td>
<td>0.363</td>
<td>0.265</td>
<td>0.417</td>
<td>0.233</td>
<td>0.216</td>
<td>0.352</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>2017877351</td>
<td>0.200</td>
<td>0.164</td>
<td>0.210</td>
<td>0.207</td>
<td>0.221</td>
<td>0.176</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>2017877359</td>
<td>0.455</td>
<td>0.169</td>
<td>0.353</td>
<td>0.212</td>
<td>0.510</td>
<td>0.265</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>2017877360</td>
<td>0.373</td>
<td>0.205</td>
<td>0.383</td>
<td>0.231</td>
<td>0.327</td>
<td>0.263</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>2017877361</td>
<td>0.405</td>
<td>0.256</td>
<td>0.324</td>
<td>0.197</td>
<td>0.391</td>
<td>0.254</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>2017877362</td>
<td>0.400</td>
<td>0.213</td>
<td>0.256</td>
<td>0.215</td>
<td>0.190</td>
<td>0.058</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>2017877363</td>
<td>0.454</td>
<td>0.215</td>
<td>0.375</td>
<td>0.165</td>
<td>0.471</td>
<td>0.243</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>2017877451</td>
<td>0.392</td>
<td>0.289</td>
<td>0.286</td>
<td>0.201</td>
<td>0.166</td>
<td>0.147</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>2017877452</td>
<td>0.463</td>
<td>0.296</td>
<td>0.313</td>
<td>0.210</td>
<td>0.250</td>
<td>0.285</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>2017877453</td>
<td>0.357</td>
<td>0.164</td>
<td>0.334</td>
<td>0.183</td>
<td>0.102</td>
<td>0.170</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>2017877454</td>
<td>0.410</td>
<td>0.233</td>
<td>0.303</td>
<td>0.197</td>
<td>0.375</td>
<td>0.403</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>2017877455</td>
<td>0.437</td>
<td>0.193</td>
<td>0.536</td>
<td>0.185</td>
<td>0.169</td>
<td>0.083</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>2017877456</td>
<td>0.479</td>
<td>0.212</td>
<td>0.321</td>
<td>0.159</td>
<td>0.341</td>
<td>0.386</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">20</td>
<td>2017877457</td>
<td>0.341</td>
<td>0.222</td>
<td>0.479</td>
<td>0.201</td>
<td>0.365</td>
<td>0.418</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">21</td>
<td>2017877458</td>
<td>0.427</td>
<td>0.316</td>
<td>0.262</td>
<td>0.181</td>
<td>0.326</td>
<td>0.377</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>2017877459</td>
<td>0.518</td>
<td>0.240</td>
<td>0.359</td>
<td>0.187</td>
<td>0.169</td>
<td>0.236</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">23</td>
<td>2017877460</td>
<td>0.314</td>
<td>0.216</td>
<td>0.342</td>
<td>0.159</td>
<td>0.157</td>
<td>0.294</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">24</td>
<td>2017877464</td>
<td>0.184</td>
<td>0.128</td>
<td>0.409</td>
<td>0.228</td>
<td>0.165</td>
<td>0.174</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">25</td>
<td>2017877465</td>
<td>0.414</td>
<td>0.210</td>
<td>0.524</td>
<td>0.200</td>
<td>0.238</td>
<td>0.130</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">26</td>
<td>2017877466</td>
<td>0.222</td>
<td>0.229</td>
<td>0.405</td>
<td>0.203</td>
<td>0.141</td>
<td>0.229</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">27</td>
<td>2017877467</td>
<td>0.137</td>
<td>0.083</td>
<td>0.316</td>
<td>0.151</td>
<td>0.258</td>
<td>0.128</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">28</td>
<td>2017877468</td>
<td>0.556</td>
<td>0.320</td>
<td>0.455</td>
<td>0.191</td>
<td>0.125</td>
<td>0.117</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">29</td>
<td>2017877469</td>
<td>0.138</td>
<td>0.101</td>
<td>0.459</td>
<td>0.223</td>
<td>0.259</td>
<td>0.166</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30</td>
<td>2017877470</td>
<td>0.274</td>
<td>0.161</td>
<td>0.467</td>
<td>0.204</td>
<td>0.214</td>
<td>0.073</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>2017877471</td>
<td>0.514</td>
<td>0.284</td>
<td>0.332</td>
<td>0.224</td>
<td>0.094</td>
<td>0.037</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">32</td>
<td>2017877472</td>
<td>0.180</td>
<td>0.108</td>
<td>0.469</td>
<td>0.225</td>
<td>0.098</td>
<td>0.039</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">33</td>
<td>2017877473</td>
<td>0.414</td>
<td>0.339</td>
<td>0.412</td>
<td>0.274</td>
<td>0.153</td>
<td>0.247</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">34</td>
<td>2017877474</td>
<td>0.518</td>
<td>0.278</td>
<td>0.527</td>
<td>0.167</td>
<td>0.112</td>
<td>0.052</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">35</td>
<td>2017877476</td>
<td>0.340</td>
<td>0.227</td>
<td>0.325</td>
<td>0.180</td>
<td>0.252</td>
<td>0.164</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">36</td>
<td>2017877477</td>
<td>0.334</td>
<td>0.175</td>
<td>0.501</td>
<td>0.156</td>
<td>0.096</td>
<td>0.037</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">37</td>
<td>2017877478</td>
<td>0.424</td>
<td>0.152</td>
<td>0.683</td>
<td>0.123</td>
<td>0.134</td>
<td>0.051</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">38</td>
<td>2017877479</td>
<td>0.456</td>
<td>0.246</td>
<td>0.564</td>
<td>0.185</td>
<td>0.115</td>
<td>0.102</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">39</td>
<td>2017877480</td>
<td>0.524</td>
<td>0.312</td>
<td>0.442</td>
<td>0.191</td>
<td>0.092</td>
<td>0.037</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">40</td>
<td>2017877481</td>
<td>0.475</td>
<td>0.242</td>
<td>0.483</td>
<td>0.156</td>
<td>0.079</td>
<td>0.029</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">41</td>
<td>2017877482</td>
<td>0.329</td>
<td>0.243</td>
<td>0.356</td>
<td>0.170</td>
<td>0.139</td>
<td>0.113</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42</td>
<td>2017877502</td>
<td>0.320</td>
<td>0.233</td>
<td>0.375</td>
<td>0.211</td>
<td>0.250</td>
<td>0.224</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43</td>
<td>2017877503</td>
<td>0.664</td>
<td>0.290</td>
<td>0.230</td>
<td>0.218</td>
<td>0.355</td>
<td>0.388</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">44</td>
<td>2017877504</td>
<td>0.522</td>
<td>0.350</td>
<td>0.330</td>
<td>0.293</td>
<td>0.087</td>
<td>0.152</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">45</td>
<td>2017877505</td>
<td>0.440</td>
<td>0.281</td>
<td>0.303</td>
<td>0.266</td>
<td>0.139</td>
<td>0.182</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">46</td>
<td>2017877506</td>
<td>0.483</td>
<td>0.233</td>
<td>0.190</td>
<td>0.210</td>
<td>0.387</td>
<td>0.270</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">47</td>
<td>2017877507</td>
<td>0.456</td>
<td>0.318</td>
<td>0.317</td>
<td>0.290</td>
<td>0.189</td>
<td>0.192</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">48</td>
<td>2017877567</td>
<td>0.275</td>
<td>0.227</td>
<td>0.486</td>
<td>0.171</td>
<td>0.103</td>
<td>0.037</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">49</td>
<td>2017877568</td>
<td>0.371</td>
<td>0.221</td>
<td>0.280</td>
<td>0.176</td>
<td>0.151</td>
<td>0.177</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="computer-vision-with-opencv" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="computer-vision-with-opencv"><span class="header-section-number">10.4</span> Computer Vision with OpenCV</h2>
<p>Working with pixel-level data gives us insights into color and basic image properties, but to access higher-level aspects like objects, faces, and poses, we need computer vision algorithms. Python’s OpenCV library provides excellent built-in capabilities for many computer vision tasks.</p>
<div id="db2be83c" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detect_objects_simple(image_path, min_area<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Simple object detection using contour finding."""</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load image</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to grayscale</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply threshold to get binary image</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    _, binary <span class="op">=</span> cv2.threshold(gray, <span class="dv">127</span>, <span class="dv">255</span>, cv2.THRESH_BINARY)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find contours</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    contours, _ <span class="op">=</span> cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract bounding boxes for large contours</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    objects <span class="op">=</span> []</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> contour <span class="kw">in</span> contours:</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        area <span class="op">=</span> cv2.contourArea(contour)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> area <span class="op">&gt;</span> min_area:</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>            x, y, w, h <span class="op">=</span> cv2.boundingRect(contour)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>            objects.append({</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">'x0'</span>: x, <span class="st">'y0'</span>: y, <span class="st">'x1'</span>: x <span class="op">+</span> w, <span class="st">'y1'</span>: y <span class="op">+</span> h,</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">'area'</span>: area, <span class="st">'confidence'</span>: area <span class="op">/</span> (img.shape[<span class="dv">0</span>] <span class="op">*</span> img.shape[<span class="dv">1</span>])</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> objects</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Test simple object detection</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>sample_image <span class="op">=</span> fsac[<span class="st">'med_path'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>simple_objects <span class="op">=</span> detect_objects_simple(sample_image)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>simple_objects</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>[{'x0': 430,
  'y0': 142,
  'x1': 950,
  'y1': 258,
  'area': 11556.5,
  'confidence': 0.015784118225524474},
 {'x0': 394,
  'y0': 61,
  'x1': 442,
  'y1': 109,
  'area': 1469.5,
  'confidence': 0.0020070749562937063},
 {'x0': 20,
  'y0': 24,
  'x1': 411,
  'y1': 260,
  'area': 33478.0,
  'confidence': 0.04572497814685315}]</code></pre>
</div>
</div>
<p>For more sophisticated object detection, we can use pre-trained models. Here’s an example using OpenCV’s DNN module with a pre-trained model:</p>
<div id="5d7bd81c" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> setup_yolo_detection():</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Set up YOLO object detection (if model files are available)."""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Note: In practice, you would download these files</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># classes = open('coco.names').read().strip().split('\n')</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return net, classes</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"YOLO model files not available in this demo"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"YOLO model setup failed - using placeholder"</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detect_faces_opencv(image_path):</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Detect faces using OpenCV's built-in cascade classifier."""</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the pre-trained face cascade</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    face_cascade <span class="op">=</span> cv2.CascadeClassifier(cv2.data.haarcascades <span class="op">+</span> <span class="st">'haarcascade_frontalface_default.xml'</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load image</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to grayscale</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Detect faces</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    faces <span class="op">=</span> face_cascade.detectMultiScale(gray, scaleFactor<span class="op">=</span><span class="fl">1.1</span>, minNeighbors<span class="op">=</span><span class="dv">5</span>, minSize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">30</span>))</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to our standard format</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    face_detections <span class="op">=</span> []</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (x, y, w, h) <span class="kw">in</span> faces:</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        face_detections.append({</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>            <span class="st">'x0'</span>: x, <span class="st">'y0'</span>: y, <span class="st">'x1'</span>: x <span class="op">+</span> w, <span class="st">'y1'</span>: y <span class="op">+</span> h,</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>            <span class="st">'confidence'</span>: <span class="fl">0.8</span>  <span class="co"># OpenCV doesn't provide confidence scores for Haar cascades</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> face_detections</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Test face detection</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>faces_detected <span class="op">=</span> detect_faces_opencv(sample_image)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>faces_detected</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>[{'x0': np.int32(360),
  'y0': np.int32(133),
  'x1': np.int32(423),
  'y1': np.int32(196),
  'confidence': 0.8}]</code></pre>
</div>
</div>
<p>Let’s create a visualization function to show detection results:</p>
<div id="34f6bc67" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_detections(image_path, detections, detection_type<span class="op">=</span><span class="st">"objects"</span>):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Visualize detection results on an image."""</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load image</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    img_rgb <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create plot</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img_rgb)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw bounding boxes</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> detection <span class="kw">in</span> detections:</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        x0, y0, x1, y1 <span class="op">=</span> detection[<span class="st">'x0'</span>], detection[<span class="st">'y0'</span>], detection[<span class="st">'x1'</span>], detection[<span class="st">'y1'</span>]</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        conf <span class="op">=</span> detection.get(<span class="st">'confidence'</span>, <span class="dv">0</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw rectangle</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        rect <span class="op">=</span> plt.Rectangle((x0, y0), x1<span class="op">-</span>x0, y1<span class="op">-</span>y0, </span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>                           fill<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'orange'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        ax.add_patch(rect)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add label</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        ax.text(x0, y0<span class="op">-</span><span class="dv">10</span>, <span class="ss">f"</span><span class="sc">{</span>detection_type<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>conf<span class="sc">:.2f}</span><span class="ss">)"</span>, </span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>               color<span class="op">=</span><span class="st">'orange'</span>, fontsize<span class="op">=</span><span class="dv">10</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>detection_type<span class="sc">.</span>title()<span class="sc">}</span><span class="ss"> Detection Results"</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize face detection results</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> faces_detected:</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    visualize_detections(sample_image, faces_detected, <span class="st">"face"</span>)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No faces detected in sample image"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="10_image_data_files/figure-html/cell-17-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="10_image_data_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For pose detection, we can use MediaPipe (if available) or create a simplified version:</p>
<div id="219a9a0f" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> detect_keypoints_simple(image_path):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Simple keypoint detection using corner detection."""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load image</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Detect corners using Harris corner detection</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    corners <span class="op">=</span> cv2.goodFeaturesToTrack(gray, maxCorners<span class="op">=</span><span class="dv">100</span>, qualityLevel<span class="op">=</span><span class="fl">0.01</span>, minDistance<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    keypoints <span class="op">=</span> []</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> corners <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> corner <span class="kw">in</span> corners:</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>            x, y <span class="op">=</span> corner.ravel()</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>            keypoints.append({</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>                <span class="st">'x'</span>: <span class="bu">float</span>(x), <span class="st">'y'</span>: <span class="bu">float</span>(y), </span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">'type'</span>: <span class="st">'corner'</span>, <span class="st">'confidence'</span>: <span class="fl">0.5</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> keypoints</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Test keypoint detection</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>keypoints <span class="op">=</span> detect_keypoints_simple(sample_image)</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(keypoints)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize keypoints</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> keypoints:</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(sample_image)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>    img_rgb <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img_rgb)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> kp <span class="kw">in</span> keypoints[:<span class="dv">20</span>]:  <span class="co"># Show first 20 keypoints</span></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>        ax.plot(kp[<span class="st">'x'</span>], kp[<span class="st">'y'</span>], <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">"Detected Keypoints"</span>)</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 100 keypoints</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="10_image_data_files/figure-html/cell-18-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="10_image_data_files/figure-html/cell-18-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Let’s create a comprehensive computer vision analysis pipeline:</p>
<div id="51fbb873" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyze_image_collection_cv(image_paths, image_ids, max_images<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Run computer vision analysis on a collection of images."""</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (path, img_id) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(image_paths[:max_images], image_ids[:max_images])):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Basic image info</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> cv2.imread(path)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>            height, width <span class="op">=</span> img.shape[:<span class="dv">2</span>]</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Face detection</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>            faces <span class="op">=</span> detect_faces_opencv(path)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simple object detection</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>            objects <span class="op">=</span> detect_objects_simple(path)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Keypoint detection</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>            keypoints <span class="op">=</span> detect_keypoints_simple(path)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>            results.append({</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>                <span class="st">'image_id'</span>: img_id,</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>                <span class="st">'width'</span>: width,</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>                <span class="st">'height'</span>: height,</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>                <span class="st">'num_faces'</span>: <span class="bu">len</span>(faces),</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>                <span class="st">'num_objects'</span>: <span class="bu">len</span>(objects),</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>                <span class="st">'num_keypoints'</span>: <span class="bu">len</span>(keypoints),</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">'faces'</span>: faces,</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">'objects'</span>: objects,</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">'keypoints'</span>: keypoints</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Processed </span><span class="sc">{</span>img_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(faces)<span class="sc">}</span><span class="ss"> faces, </span><span class="sc">{</span><span class="bu">len</span>(objects)<span class="sc">}</span><span class="ss"> objects, </span><span class="sc">{</span><span class="bu">len</span>(keypoints)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Error processing </span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Run computer vision analysis on sample images</span></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>cv_results <span class="op">=</span> analyze_image_collection_cv(</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'med_path'</span>].iloc[:<span class="dv">10</span>].tolist(),</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'filename'</span>].iloc[:<span class="dv">10</span>].tolist()</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Create summary DataFrame</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>cv_summary <span class="op">=</span> pd.DataFrame([</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>    {k: v <span class="cf">for</span> k, v <span class="kw">in</span> result.items() </span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>     <span class="cf">if</span> k <span class="kw">not</span> <span class="kw">in</span> [<span class="st">'faces'</span>, <span class="st">'objects'</span>, <span class="st">'keypoints'</span>]}</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> result <span class="kw">in</span> cv_results</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>cv_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processed 2017877351: 1 faces, 3 objects, 100 keypoints</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[ WARN:0@2.586] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877359.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877451.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877502.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877452.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877453.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877454.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877476.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877477.jpg'): can't open/read file: check file path/integrity
[ WARN:0@2.587] global loadsave.cpp:268 findDecoder imread_('data/fsac/med/2017877478.jpg'): can't open/read file: check file path/integrity</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">image_id</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">height</th>
<th data-quarto-table-cell-role="th">num_faces</th>
<th data-quarto-table-cell-role="th">num_objects</th>
<th data-quarto-table-cell-role="th">num_keypoints</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877351</td>
<td>1024</td>
<td>715</td>
<td>1</td>
<td>3</td>
<td>100</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="embeddings-and-similarity" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="embeddings-and-similarity"><span class="header-section-number">10.5</span> Embeddings and Similarity</h2>
<p>For more sophisticated analysis, we can compute image embeddings using pre-trained deep learning models. These embeddings capture high-level semantic features and can be used for similarity analysis and clustering:</p>
<div id="d3fbfc53" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_simple_image_features(image_path):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute simple statistical features from an image."""</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> cv2.imread(image_path)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to different color spaces</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    img_rgb <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    img_hsv <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2HSV)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    img_gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> {}</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Color statistics</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, color <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">'red'</span>, <span class="st">'green'</span>, <span class="st">'blue'</span>]):</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        features[<span class="ss">f'</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">_mean'</span>] <span class="op">=</span> np.mean(img_rgb[:, :, i])</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        features[<span class="ss">f'</span><span class="sc">{</span>color<span class="sc">}</span><span class="ss">_std'</span>] <span class="op">=</span> np.std(img_rgb[:, :, i])</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># HSV statistics</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, channel <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">'hue'</span>, <span class="st">'saturation'</span>, <span class="st">'value'</span>]):</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>        features[<span class="ss">f'</span><span class="sc">{</span>channel<span class="sc">}</span><span class="ss">_mean'</span>] <span class="op">=</span> np.mean(img_hsv[:, :, i])</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        features[<span class="ss">f'</span><span class="sc">{</span>channel<span class="sc">}</span><span class="ss">_std'</span>] <span class="op">=</span> np.std(img_hsv[:, :, i])</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Texture features (simple)</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    features[<span class="st">'brightness_mean'</span>] <span class="op">=</span> np.mean(img_gray)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    features[<span class="st">'brightness_std'</span>] <span class="op">=</span> np.std(img_gray)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Edge density</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    edges <span class="op">=</span> cv2.Canny(img_gray, <span class="dv">50</span>, <span class="dv">150</span>)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    features[<span class="st">'edge_density'</span>] <span class="op">=</span> np.<span class="bu">sum</span>(edges <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">/</span> (edges.shape[<span class="dv">0</span>] <span class="op">*</span> edges.shape[<span class="dv">1</span>])</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> features</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_collection_features(image_paths, image_ids, max_images<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute features for a collection of images."""</span></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    feature_list <span class="op">=</span> []</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> path, img_id <span class="kw">in</span> <span class="bu">zip</span>(image_paths[:max_images], image_ids[:max_images]):</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> compute_simple_image_features(path)</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> features:</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>            features[<span class="st">'image_id'</span>] <span class="op">=</span> img_id</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>            feature_list.append(features)</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(feature_list)</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>feature_df <span class="op">=</span> compute_collection_features(</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'thm_path'</span>].iloc[:<span class="dv">50</span>].tolist(),</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>    fsac[<span class="st">'filename'</span>].iloc[:<span class="dv">50</span>].tolist()</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>feature_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">red_mean</th>
<th data-quarto-table-cell-role="th">red_std</th>
<th data-quarto-table-cell-role="th">green_mean</th>
<th data-quarto-table-cell-role="th">green_std</th>
<th data-quarto-table-cell-role="th">blue_mean</th>
<th data-quarto-table-cell-role="th">blue_std</th>
<th data-quarto-table-cell-role="th">hue_mean</th>
<th data-quarto-table-cell-role="th">hue_std</th>
<th data-quarto-table-cell-role="th">saturation_mean</th>
<th data-quarto-table-cell-role="th">saturation_std</th>
<th data-quarto-table-cell-role="th">value_mean</th>
<th data-quarto-table-cell-role="th">value_std</th>
<th data-quarto-table-cell-role="th">brightness_mean</th>
<th data-quarto-table-cell-role="th">brightness_std</th>
<th data-quarto-table-cell-role="th">edge_density</th>
<th data-quarto-table-cell-role="th">image_id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>48.400508</td>
<td>41.475860</td>
<td>49.190667</td>
<td>40.614180</td>
<td>42.465016</td>
<td>41.579156</td>
<td>39.775937</td>
<td>31.769777</td>
<td>53.497968</td>
<td>52.802824</td>
<td>51.033778</td>
<td>41.706693</td>
<td>48.188381</td>
<td>40.814655</td>
<td>0.113206</td>
<td>2017877351</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>81.737016</td>
<td>34.318035</td>
<td>92.810222</td>
<td>33.641454</td>
<td>107.396762</td>
<td>52.315815</td>
<td>91.775365</td>
<td>47.634042</td>
<td>90.064635</td>
<td>53.936588</td>
<td>116.089206</td>
<td>42.968344</td>
<td>91.170984</td>
<td>33.932754</td>
<td>0.167683</td>
<td>2017877359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>97.744050</td>
<td>70.886472</td>
<td>91.299315</td>
<td>75.889849</td>
<td>82.681433</td>
<td>75.932099</td>
<td>29.883863</td>
<td>26.440304</td>
<td>73.054891</td>
<td>51.338140</td>
<td>99.904984</td>
<td>73.569285</td>
<td>92.242866</td>
<td>74.179275</td>
<td>0.158442</td>
<td>2017877451</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>73.825016</td>
<td>51.435218</td>
<td>70.491238</td>
<td>50.981097</td>
<td>65.652190</td>
<td>60.002446</td>
<td>45.058286</td>
<td>40.352350</td>
<td>95.624317</td>
<td>53.756969</td>
<td>81.643937</td>
<td>59.347840</td>
<td>70.930286</td>
<td>51.548233</td>
<td>0.248254</td>
<td>2017877502</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>114.542704</td>
<td>70.704723</td>
<td>102.673774</td>
<td>73.155934</td>
<td>98.347862</td>
<td>83.224801</td>
<td>45.060189</td>
<td>51.326862</td>
<td>79.936541</td>
<td>53.647151</td>
<td>118.026289</td>
<td>75.601807</td>
<td>105.729497</td>
<td>73.363660</td>
<td>0.167044</td>
<td>2017877452</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>90.941807</td>
<td>41.897665</td>
<td>75.283427</td>
<td>39.747231</td>
<td>66.043676</td>
<td>42.456560</td>
<td>18.371464</td>
<td>30.693423</td>
<td>85.291464</td>
<td>46.579038</td>
<td>90.954704</td>
<td>41.917770</td>
<td>78.925857</td>
<td>40.368988</td>
<td>0.184299</td>
<td>2017877453</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>104.533019</td>
<td>59.477602</td>
<td>86.994214</td>
<td>55.888445</td>
<td>85.665472</td>
<td>64.829710</td>
<td>67.479434</td>
<td>72.607520</td>
<td>77.228113</td>
<td>50.234260</td>
<td>104.647044</td>
<td>59.514555</td>
<td>92.084906</td>
<td>57.737912</td>
<td>0.168302</td>
<td>2017877454</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>78.401761</td>
<td>58.667437</td>
<td>77.667044</td>
<td>49.386170</td>
<td>63.018994</td>
<td>47.942323</td>
<td>45.443270</td>
<td>29.527433</td>
<td>82.890440</td>
<td>45.851045</td>
<td>86.798868</td>
<td>57.863629</td>
<td>76.222767</td>
<td>50.998238</td>
<td>0.235094</td>
<td>2017877476</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>85.103689</td>
<td>44.593655</td>
<td>66.680518</td>
<td>36.546528</td>
<td>46.175987</td>
<td>31.868088</td>
<td>17.351974</td>
<td>6.734589</td>
<td>127.793010</td>
<td>39.809223</td>
<td>85.212492</td>
<td>44.509765</td>
<td>69.849579</td>
<td>38.230333</td>
<td>0.198317</td>
<td>2017877477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>103.995107</td>
<td>42.500780</td>
<td>86.104343</td>
<td>27.884789</td>
<td>34.435535</td>
<td>17.689883</td>
<td>24.068746</td>
<td>9.131813</td>
<td>174.141468</td>
<td>31.383043</td>
<td>108.034862</td>
<td>38.775356</td>
<td>85.568379</td>
<td>29.842472</td>
<td>0.270887</td>
<td>2017877478</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>46.029221</td>
<td>31.148973</td>
<td>40.476822</td>
<td>31.229591</td>
<td>33.451963</td>
<td>33.979990</td>
<td>29.774891</td>
<td>31.326865</td>
<td>104.225545</td>
<td>58.087727</td>
<td>46.894143</td>
<td>32.561435</td>
<td>41.329533</td>
<td>31.331805</td>
<td>0.219502</td>
<td>2017877464</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>88.117547</td>
<td>58.875582</td>
<td>99.467233</td>
<td>48.976304</td>
<td>67.708302</td>
<td>46.038911</td>
<td>42.815346</td>
<td>23.450040</td>
<td>133.517233</td>
<td>51.010242</td>
<td>105.664465</td>
<td>53.483034</td>
<td>92.440000</td>
<td>49.643096</td>
<td>0.178616</td>
<td>2017877465</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>80.464403</td>
<td>53.644418</td>
<td>79.787925</td>
<td>49.894952</td>
<td>81.904214</td>
<td>48.724543</td>
<td>58.980503</td>
<td>47.347917</td>
<td>97.597673</td>
<td>58.791086</td>
<td>95.154214</td>
<td>52.215025</td>
<td>80.216415</td>
<td>50.056749</td>
<td>0.141509</td>
<td>2017877360</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>56.463585</td>
<td>58.369474</td>
<td>47.968176</td>
<td>55.052475</td>
<td>39.383522</td>
<td>47.941876</td>
<td>25.389119</td>
<td>41.353267</td>
<td>103.409623</td>
<td>51.688912</td>
<td>56.499560</td>
<td>58.359475</td>
<td>49.513648</td>
<td>55.166156</td>
<td>0.174969</td>
<td>2017877466</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>51.283333</td>
<td>20.744105</td>
<td>42.429811</td>
<td>18.389210</td>
<td>34.882893</td>
<td>20.235963</td>
<td>17.420000</td>
<td>17.254465</td>
<td>92.220314</td>
<td>27.652024</td>
<td>52.006352</td>
<td>22.368386</td>
<td>44.225157</td>
<td>19.091725</td>
<td>0.138931</td>
<td>2017877342</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>30.806791</td>
<td>20.283864</td>
<td>33.733333</td>
<td>19.997104</td>
<td>26.770218</td>
<td>19.833903</td>
<td>46.528349</td>
<td>22.967456</td>
<td>80.602181</td>
<td>38.444274</td>
<td>34.837009</td>
<td>21.188158</td>
<td>32.065047</td>
<td>19.762150</td>
<td>0.154766</td>
<td>2017877467</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>140.041132</td>
<td>83.657134</td>
<td>116.557987</td>
<td>69.169553</td>
<td>83.198553</td>
<td>60.791438</td>
<td>22.443019</td>
<td>21.081217</td>
<td>115.921195</td>
<td>48.575539</td>
<td>141.748868</td>
<td>81.713885</td>
<td>119.781258</td>
<td>71.880525</td>
<td>0.178113</td>
<td>2017877468</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>29.393832</td>
<td>26.267049</td>
<td>32.070093</td>
<td>20.981113</td>
<td>20.809533</td>
<td>14.670913</td>
<td>46.635140</td>
<td>29.843974</td>
<td>117.120935</td>
<td>56.957853</td>
<td>35.202243</td>
<td>25.740949</td>
<td>29.992835</td>
<td>20.992187</td>
<td>0.140810</td>
<td>2017877469</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>114.696699</td>
<td>64.524285</td>
<td>86.043107</td>
<td>51.108452</td>
<td>53.625761</td>
<td>39.613265</td>
<td>20.471650</td>
<td>17.487386</td>
<td>143.762265</td>
<td>47.188142</td>
<td>116.154693</td>
<td>62.774065</td>
<td>90.923430</td>
<td>52.586304</td>
<td>0.225178</td>
<td>2017877479</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>133.595937</td>
<td>79.780805</td>
<td>108.270032</td>
<td>69.069737</td>
<td>84.055873</td>
<td>61.292142</td>
<td>16.655429</td>
<td>6.647568</td>
<td>112.837587</td>
<td>48.741106</td>
<td>133.745587</td>
<td>79.664680</td>
<td>113.081905</td>
<td>71.063085</td>
<td>0.241778</td>
<td>2017877480</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">20</td>
<td>121.080312</td>
<td>61.701089</td>
<td>91.278505</td>
<td>50.547611</td>
<td>68.514393</td>
<td>43.820969</td>
<td>14.248474</td>
<td>5.178310</td>
<td>123.070530</td>
<td>39.742824</td>
<td>121.091215</td>
<td>61.683820</td>
<td>97.595888</td>
<td>52.810299</td>
<td>0.243489</td>
<td>2017877481</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">21</td>
<td>63.123654</td>
<td>41.499078</td>
<td>67.705000</td>
<td>38.578434</td>
<td>42.180256</td>
<td>34.951649</td>
<td>38.582821</td>
<td>13.073875</td>
<td>119.070833</td>
<td>52.056702</td>
<td>69.988077</td>
<td>40.957797</td>
<td>63.436154</td>
<td>38.553044</td>
<td>0.173013</td>
<td>2017877470</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>112.844843</td>
<td>75.487786</td>
<td>93.777296</td>
<td>72.134660</td>
<td>80.970000</td>
<td>80.597369</td>
<td>44.146541</td>
<td>58.727533</td>
<td>104.437673</td>
<td>61.520492</td>
<td>113.003333</td>
<td>75.465808</td>
<td>98.015220</td>
<td>73.709413</td>
<td>0.194340</td>
<td>2017877343</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">23</td>
<td>83.955409</td>
<td>47.792707</td>
<td>87.647484</td>
<td>54.406412</td>
<td>95.537107</td>
<td>71.284159</td>
<td>70.519497</td>
<td>45.667125</td>
<td>82.656792</td>
<td>50.236148</td>
<td>103.149057</td>
<td>65.184305</td>
<td>87.420314</td>
<td>54.102078</td>
<td>0.252390</td>
<td>2017877361</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">24</td>
<td>104.506231</td>
<td>55.376375</td>
<td>92.864735</td>
<td>41.541625</td>
<td>53.817695</td>
<td>39.107500</td>
<td>30.355701</td>
<td>14.916474</td>
<td>136.764860</td>
<td>47.032520</td>
<td>111.503988</td>
<td>49.272488</td>
<td>91.906355</td>
<td>43.659127</td>
<td>0.156075</td>
<td>2017877455</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">25</td>
<td>131.048553</td>
<td>72.518141</td>
<td>118.334025</td>
<td>69.348181</td>
<td>102.083333</td>
<td>73.681824</td>
<td>16.896855</td>
<td>6.660344</td>
<td>84.622138</td>
<td>57.147190</td>
<td>131.070755</td>
<td>72.499301</td>
<td>120.282013</td>
<td>70.675849</td>
<td>0.145094</td>
<td>2017877471</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">26</td>
<td>88.017524</td>
<td>36.580735</td>
<td>93.506921</td>
<td>29.687433</td>
<td>65.010857</td>
<td>25.655225</td>
<td>41.531111</td>
<td>23.905056</td>
<td>110.723175</td>
<td>37.161830</td>
<td>104.220000</td>
<td>29.348683</td>
<td>88.615429</td>
<td>28.466124</td>
<td>0.094032</td>
<td>2017877344</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">27</td>
<td>118.074167</td>
<td>50.137306</td>
<td>90.503910</td>
<td>44.484185</td>
<td>93.987372</td>
<td>55.462395</td>
<td>61.407821</td>
<td>69.468353</td>
<td>81.986346</td>
<td>40.526672</td>
<td>122.123846</td>
<td>54.057065</td>
<td>99.156859</td>
<td>46.321126</td>
<td>0.175769</td>
<td>2017877456</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">28</td>
<td>107.324969</td>
<td>51.047631</td>
<td>82.669434</td>
<td>49.075978</td>
<td>73.490314</td>
<td>59.307326</td>
<td>42.140000</td>
<td>53.256418</td>
<td>110.607987</td>
<td>58.586672</td>
<td>110.083648</td>
<td>54.318929</td>
<td>89.003585</td>
<td>49.756400</td>
<td>0.199937</td>
<td>2017877345</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">29</td>
<td>85.194032</td>
<td>55.983384</td>
<td>53.284762</td>
<td>40.397759</td>
<td>51.987746</td>
<td>39.404361</td>
<td>64.951683</td>
<td>75.012786</td>
<td>122.258222</td>
<td>51.126180</td>
<td>87.053651</td>
<td>56.545085</td>
<td>62.678222</td>
<td>43.669581</td>
<td>0.248698</td>
<td>2017877457</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30</td>
<td>108.352516</td>
<td>79.922961</td>
<td>95.744780</td>
<td>76.768345</td>
<td>96.656226</td>
<td>85.737011</td>
<td>58.679874</td>
<td>67.826045</td>
<td>66.842138</td>
<td>46.196735</td>
<td>108.805975</td>
<td>80.528130</td>
<td>99.629748</td>
<td>78.684406</td>
<td>0.157107</td>
<td>2017877458</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>131.498679</td>
<td>61.323750</td>
<td>105.265849</td>
<td>53.244667</td>
<td>90.536792</td>
<td>56.800095</td>
<td>30.496604</td>
<td>42.434521</td>
<td>91.494403</td>
<td>47.751074</td>
<td>132.156855</td>
<td>61.293471</td>
<td>111.435723</td>
<td>55.296977</td>
<td>0.229057</td>
<td>2017877459</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">32</td>
<td>45.761761</td>
<td>27.493175</td>
<td>38.016478</td>
<td>26.769528</td>
<td>28.693270</td>
<td>27.423319</td>
<td>17.626226</td>
<td>7.086064</td>
<td>119.520189</td>
<td>57.403468</td>
<td>45.775535</td>
<td>27.493985</td>
<td>39.232138</td>
<td>26.905713</td>
<td>0.212390</td>
<td>2017877472</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">33</td>
<td>80.010692</td>
<td>54.969323</td>
<td>62.417987</td>
<td>51.127407</td>
<td>58.610252</td>
<td>54.909580</td>
<td>28.257736</td>
<td>52.926363</td>
<td>87.285409</td>
<td>40.673930</td>
<td>80.068553</td>
<td>55.012647</td>
<td>67.255975</td>
<td>52.453130</td>
<td>0.194969</td>
<td>2017877460</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">34</td>
<td>99.555389</td>
<td>53.394896</td>
<td>100.796573</td>
<td>54.881495</td>
<td>85.679315</td>
<td>55.164719</td>
<td>34.291526</td>
<td>10.411720</td>
<td>65.177695</td>
<td>54.740345</td>
<td>102.049470</td>
<td>54.370190</td>
<td>98.713209</td>
<td>54.386002</td>
<td>0.264860</td>
<td>2017877362</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">35</td>
<td>84.579231</td>
<td>45.528596</td>
<td>93.027372</td>
<td>52.577467</td>
<td>111.196538</td>
<td>63.506668</td>
<td>86.903077</td>
<td>42.282229</td>
<td>87.402885</td>
<td>32.531759</td>
<td>115.887308</td>
<td>59.344075</td>
<td>92.579551</td>
<td>51.261890</td>
<td>0.088333</td>
<td>2017877346</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">36</td>
<td>90.322804</td>
<td>43.053227</td>
<td>94.376760</td>
<td>50.783611</td>
<td>97.602430</td>
<td>61.829366</td>
<td>62.398754</td>
<td>45.545427</td>
<td>79.625358</td>
<td>34.789595</td>
<td>109.144611</td>
<td>56.291571</td>
<td>93.536075</td>
<td>49.034670</td>
<td>0.140000</td>
<td>2017877347</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">37</td>
<td>88.765309</td>
<td>43.570880</td>
<td>76.093765</td>
<td>42.608659</td>
<td>62.137593</td>
<td>44.942232</td>
<td>37.559753</td>
<td>39.817389</td>
<td>108.256481</td>
<td>72.285519</td>
<td>90.678086</td>
<td>44.265872</td>
<td>78.307160</td>
<td>42.365317</td>
<td>0.182469</td>
<td>2017877348</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">38</td>
<td>105.534642</td>
<td>86.401182</td>
<td>92.838442</td>
<td>84.042813</td>
<td>80.757570</td>
<td>76.714898</td>
<td>27.611215</td>
<td>44.547005</td>
<td>105.054829</td>
<td>69.975641</td>
<td>105.564424</td>
<td>86.373293</td>
<td>95.252150</td>
<td>83.825594</td>
<td>0.171589</td>
<td>2017877473</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">39</td>
<td>92.470818</td>
<td>67.667208</td>
<td>71.538365</td>
<td>64.420894</td>
<td>64.385723</td>
<td>64.140160</td>
<td>38.828491</td>
<td>63.431995</td>
<td>106.236604</td>
<td>59.359783</td>
<td>92.507296</td>
<td>67.636949</td>
<td>76.988302</td>
<td>64.900958</td>
<td>0.245157</td>
<td>2017877349</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">40</td>
<td>130.924112</td>
<td>72.598522</td>
<td>105.936822</td>
<td>59.958414</td>
<td>68.812773</td>
<td>52.343166</td>
<td>20.118069</td>
<td>9.414985</td>
<td>134.368660</td>
<td>42.538129</td>
<td>132.216449</td>
<td>70.958982</td>
<td>109.182056</td>
<td>62.398751</td>
<td>0.248536</td>
<td>2017877474</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">41</td>
<td>83.497072</td>
<td>61.303352</td>
<td>76.018380</td>
<td>59.838535</td>
<td>60.752773</td>
<td>60.077649</td>
<td>25.000561</td>
<td>20.286489</td>
<td>90.802430</td>
<td>43.277838</td>
<td>83.862804</td>
<td>61.846403</td>
<td>76.500748</td>
<td>60.107136</td>
<td>0.249782</td>
<td>2017877482</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42</td>
<td>70.171006</td>
<td>57.888985</td>
<td>59.330063</td>
<td>53.629693</td>
<td>41.949811</td>
<td>48.892699</td>
<td>18.583648</td>
<td>6.622317</td>
<td>123.992956</td>
<td>43.570178</td>
<td>70.174465</td>
<td>57.892657</td>
<td>60.553459</td>
<td>54.240271</td>
<td>0.180943</td>
<td>2017877567</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43</td>
<td>94.099748</td>
<td>56.198674</td>
<td>87.077044</td>
<td>56.124668</td>
<td>76.402516</td>
<td>59.515188</td>
<td>27.279748</td>
<td>31.800421</td>
<td>71.458805</td>
<td>44.877237</td>
<td>94.490881</td>
<td>56.308112</td>
<td>87.936918</td>
<td>56.484562</td>
<td>0.243648</td>
<td>2017877568</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">44</td>
<td>168.825109</td>
<td>73.687059</td>
<td>153.781059</td>
<td>74.056368</td>
<td>145.944486</td>
<td>84.331388</td>
<td>63.854330</td>
<td>69.786665</td>
<td>58.674579</td>
<td>55.574706</td>
<td>169.404112</td>
<td>73.941302</td>
<td>157.375514</td>
<td>74.742409</td>
<td>0.141994</td>
<td>2017877503</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">45</td>
<td>76.960127</td>
<td>36.188942</td>
<td>86.720952</td>
<td>40.734122</td>
<td>111.875683</td>
<td>58.086648</td>
<td>84.822794</td>
<td>43.809358</td>
<td>95.568254</td>
<td>42.008150</td>
<td>115.743492</td>
<td>54.796816</td>
<td>86.664317</td>
<td>40.626921</td>
<td>0.096698</td>
<td>2017877363</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">46</td>
<td>133.133580</td>
<td>89.401335</td>
<td>119.274877</td>
<td>91.495096</td>
<td>111.279815</td>
<td>93.325801</td>
<td>15.625370</td>
<td>27.375764</td>
<td>84.168580</td>
<td>74.792512</td>
<td>133.177778</td>
<td>89.336956</td>
<td>122.491235</td>
<td>90.884541</td>
<td>0.111235</td>
<td>2017877504</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">47</td>
<td>111.843899</td>
<td>71.251858</td>
<td>101.079748</td>
<td>76.245654</td>
<td>93.466415</td>
<td>79.543390</td>
<td>24.982893</td>
<td>32.840163</td>
<td>77.272327</td>
<td>67.767440</td>
<td>112.257547</td>
<td>71.599541</td>
<td>103.443836</td>
<td>74.930240</td>
<td>0.182767</td>
<td>2017877505</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">48</td>
<td>119.622099</td>
<td>58.099497</td>
<td>115.272840</td>
<td>60.504509</td>
<td>110.890062</td>
<td>66.012334</td>
<td>69.721358</td>
<td>48.616354</td>
<td>48.421111</td>
<td>53.642553</td>
<td>123.180432</td>
<td>59.428493</td>
<td>116.087778</td>
<td>60.107041</td>
<td>0.119630</td>
<td>2017877506</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">49</td>
<td>114.958069</td>
<td>79.891562</td>
<td>106.626044</td>
<td>85.110892</td>
<td>98.143115</td>
<td>87.225182</td>
<td>33.995265</td>
<td>34.686077</td>
<td>80.942181</td>
<td>74.002898</td>
<td>116.392835</td>
<td>81.056980</td>
<td>108.146293</td>
<td>83.496321</td>
<td>0.113707</td>
<td>2017877507</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now let’s apply dimensionality reduction to visualize image similarities:</p>
<div id="9aa14a6e" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare features for PCA</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>feature_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> feature_df.columns <span class="cf">if</span> col <span class="op">!=</span> <span class="st">'image_id'</span>]</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> feature_df[feature_columns].fillna(<span class="dv">0</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize features</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PCA results DataFrame</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>pca_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'image_id'</span>: feature_df[<span class="st">'image_id'</span>],</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pca_1'</span>: X_pca[:, <span class="dv">0</span>],</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pca_2'</span>: X_pca[:, <span class="dv">1</span>]</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>pca_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">image_id</th>
<th data-quarto-table-cell-role="th">pca_1</th>
<th data-quarto-table-cell-role="th">pca_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2017877351</td>
<td>-3.127072</td>
<td>1.665120</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2017877359</td>
<td>-0.517014</td>
<td>2.935728</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2017877451</td>
<td>2.182675</td>
<td>-0.230172</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2017877502</td>
<td>-0.764665</td>
<td>-0.001976</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2017877452</td>
<td>3.276433</td>
<td>0.628718</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>2017877453</td>
<td>-1.626051</td>
<td>-0.114354</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>2017877454</td>
<td>1.235817</td>
<td>2.093015</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>2017877476</td>
<td>-0.766439</td>
<td>-0.115455</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>2017877477</td>
<td>-2.806650</td>
<td>-1.711391</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>2017877478</td>
<td>-3.120399</td>
<td>-2.976461</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>2017877464</td>
<td>-4.592952</td>
<td>-0.079803</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>2017877465</td>
<td>-0.264505</td>
<td>-0.788520</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>2017877360</td>
<td>-0.278584</td>
<td>1.376681</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>2017877466</td>
<td>-2.038128</td>
<td>-0.372860</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>2017877342</td>
<td>-5.865411</td>
<td>0.374106</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>2017877467</td>
<td>-6.333913</td>
<td>1.437603</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>2017877468</td>
<td>3.392902</td>
<td>-2.002574</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>2017877469</td>
<td>-6.191182</td>
<td>0.862197</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>2017877479</td>
<td>-0.156366</td>
<td>-2.541662</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>2017877480</td>
<td>2.828061</td>
<td>-2.782250</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">20</td>
<td>2017877481</td>
<td>0.175330</td>
<td>-2.611386</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">21</td>
<td>2017877470</td>
<td>-3.040966</td>
<td>-0.487636</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>2017877343</td>
<td>2.840998</td>
<td>-0.069829</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">23</td>
<td>2017877361</td>
<td>0.740963</td>
<td>1.222461</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">24</td>
<td>2017877455</td>
<td>-0.898692</td>
<td>-1.308494</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">25</td>
<td>2017877471</td>
<td>3.441209</td>
<td>-1.187316</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">26</td>
<td>2017877344</td>
<td>-2.383073</td>
<td>0.805373</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">27</td>
<td>2017877456</td>
<td>0.752780</td>
<td>1.947859</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">28</td>
<td>2017877345</td>
<td>0.256852</td>
<td>0.211766</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">29</td>
<td>2017877457</td>
<td>-1.645298</td>
<td>0.660495</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30</td>
<td>2017877458</td>
<td>3.486211</td>
<td>1.530484</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>2017877459</td>
<td>1.792946</td>
<td>-0.527547</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">32</td>
<td>2017877472</td>
<td>-5.386289</td>
<td>-1.103713</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">33</td>
<td>2017877460</td>
<td>-1.076615</td>
<td>0.246536</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">34</td>
<td>2017877362</td>
<td>0.611694</td>
<td>-0.668645</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">35</td>
<td>2017877346</td>
<td>0.681692</td>
<td>2.974980</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">36</td>
<td>2017877347</td>
<td>0.357926</td>
<td>2.017856</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">37</td>
<td>2017877348</td>
<td>-1.173296</td>
<td>0.134348</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">38</td>
<td>2017877473</td>
<td>3.401338</td>
<td>-1.014099</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">39</td>
<td>2017877349</td>
<td>0.772427</td>
<td>-0.348489</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">40</td>
<td>2017877474</td>
<td>1.598779</td>
<td>-2.943730</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">41</td>
<td>2017877482</td>
<td>-0.273172</td>
<td>-1.280374</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42</td>
<td>2017877567</td>
<td>-1.910482</td>
<td>-1.780760</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43</td>
<td>2017877568</td>
<td>0.249913</td>
<td>-0.383483</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">44</td>
<td>2017877503</td>
<td>6.551172</td>
<td>2.086539</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">45</td>
<td>2017877363</td>
<td>-0.215369</td>
<td>3.046338</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">46</td>
<td>2017877504</td>
<td>5.726072</td>
<td>-0.918033</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">47</td>
<td>2017877505</td>
<td>3.097225</td>
<td>-0.485688</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">48</td>
<td>2017877506</td>
<td>2.728169</td>
<td>2.541285</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">49</td>
<td>2017877507</td>
<td>4.272999</td>
<td>0.037212</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Let’s visualize the PCA results:</p>
<div id="02cc6b45" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PCA visualization with actual images</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">12</span>))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot points</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> ax.scatter(pca_results[<span class="st">'pca_1'</span>], pca_results[<span class="st">'pca_2'</span>], alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a few sample images to the plot</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.offsetbox <span class="im">import</span> OffsetImage, AnnotationBbox</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Select a few representative points</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>sample_indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(pca_results), size<span class="op">=</span><span class="bu">min</span>(<span class="dv">12</span>, <span class="bu">len</span>(pca_results)), replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> sample_indices:</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> pca_results.iloc[idx]</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    img_path <span class="op">=</span> fsac[fsac[<span class="st">'filename'</span>] <span class="op">==</span> row[<span class="st">'image_id'</span>]][<span class="st">'thm_path'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> plt.imread(img_path)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Resize image for display</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>        img_resized <span class="op">=</span> cv2.resize(img, (<span class="dv">50</span>, <span class="dv">50</span>))</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>        imagebox <span class="op">=</span> OffsetImage(img_resized, zoom<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>        ab <span class="op">=</span> AnnotationBbox(imagebox, (row[<span class="st">'pca_1'</span>], row[<span class="st">'pca_2'</span>]), frameon<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>        ax.add_artist(ab)</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If image loading fails, just plot a point</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>        ax.plot(row[<span class="st">'pca_1'</span>], row[<span class="st">'pca_2'</span>], <span class="st">'rx'</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="ss">f'First Principal Component (explains </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of variance)'</span>)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="ss">f'Second Principal Component (explains </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss"> of variance)'</span>)</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Image Collection Visualization using PCA'</span>)</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="10_image_data_files/figure-html/cell-22-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="10_image_data_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For comparison, let’s also try UMAP:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply UMAP for comparison</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>umap_reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>X_umap <span class="op">=</span> umap_reducer.fit_transform(X_scaled)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>umap_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'image_id'</span>: feature_df[<span class="st">'image_id'</span>],</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'umap_1'</span>: X_umap[:, <span class="dv">0</span>],</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'umap_2'</span>: X_umap[:, <span class="dv">1</span>]</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"UMAP results:"</span>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(umap_results.head())</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot UMAP results</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>p_umap <span class="op">=</span> (ggplot(umap_results, aes(x<span class="op">=</span><span class="st">'umap_1'</span>, y<span class="op">=</span><span class="st">'umap_2'</span>)) <span class="op">+</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>          geom_point(size<span class="op">=</span><span class="dv">3</span>, alpha<span class="op">=</span><span class="fl">0.7</span>) <span class="op">+</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>          labs(title<span class="op">=</span><span class="st">"Image Collection UMAP Visualization"</span>,</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>               x<span class="op">=</span><span class="st">"UMAP Dimension 1"</span>, y<span class="op">=</span><span class="st">"UMAP Dimension 2"</span>) <span class="op">+</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>          theme_minimal())</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>p_umap</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, let’s create a simple image similarity function:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_similar_images(target_image_id, feature_df, pca_results, n_similar<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Find images similar to a target image based on PCA coordinates."""</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> euclidean_distances</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get target image features</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    target_row <span class="op">=</span> pca_results[pca_results[<span class="st">'image_id'</span>] <span class="op">==</span> target_image_id]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> target_row.empty:</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    target_coords <span class="op">=</span> target_row[[<span class="st">'pca_1'</span>, <span class="st">'pca_2'</span>]].values</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    all_coords <span class="op">=</span> pca_results[[<span class="st">'pca_1'</span>, <span class="st">'pca_2'</span>]].values</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute distances</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    distances <span class="op">=</span> euclidean_distances(target_coords, all_coords)[<span class="dv">0</span>]</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of most similar images (excluding the target itself)</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    similar_indices <span class="op">=</span> np.argsort(distances)[<span class="dv">1</span>:n_similar<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    similar_images <span class="op">=</span> pca_results.iloc[similar_indices]</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    similar_images[<span class="st">'distance'</span>] <span class="op">=</span> distances[similar_indices]</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> similar_images</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Find similar images for the first image</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>target_id <span class="op">=</span> feature_df[<span class="st">'image_id'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>similar <span class="op">=</span> find_similar_images(target_id, feature_df, pca_results)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Images similar to </span><span class="sc">{</span>target_id<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(similar)</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the target and similar images</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> similar <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    axes <span class="op">=</span> axes.flatten()</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show target image first</span></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    target_path <span class="op">=</span> fsac[fsac[<span class="st">'filename'</span>] <span class="op">==</span> target_id][<span class="st">'thm_path'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    target_img <span class="op">=</span> plt.imread(target_path)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].imshow(target_img)</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="ss">f"Target: </span><span class="sc">{</span>target_id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show similar images</span></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (_, row) <span class="kw">in</span> <span class="bu">enumerate</span>(similar.iterrows()):</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&gt;=</span> <span class="dv">5</span>:  <span class="co"># Only show 5 similar images</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> fsac[fsac[<span class="st">'filename'</span>] <span class="op">==</span> row[<span class="st">'image_id'</span>]][<span class="st">'thm_path'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> plt.imread(img_path)</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>        axes[i<span class="op">+</span><span class="dv">1</span>].imshow(img)</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>        axes[i<span class="op">+</span><span class="dv">1</span>].set_title(<span class="ss">f"Similar: </span><span class="sc">{</span>row[<span class="st">'image_id'</span>][:<span class="dv">8</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">Dist: </span><span class="sc">{</span>row[<span class="st">'distance'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>        axes[i<span class="op">+</span><span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extensions" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="extensions"><span class="header-section-number">10.6</span> Extensions</h2>
<p>In this chapter we have shown how Python’s rich ecosystem enables direct analysis of image collections without requiring external wrappers. Our focus has been on practical techniques for extracting meaningful information from visual data using established computer vision and machine learning approaches.</p>
<p><strong>For deeper computer vision work:</strong></p>
<ul>
<li><strong>OpenCV</strong> provides comprehensive computer vision functionality</li>
<li><strong>MediaPipe</strong> offers robust pose detection, face mesh, and holistic analysis</li>
<li><strong>scikit-image</strong> has extensive image processing capabilities</li>
<li><strong>Pillow (PIL)</strong> handles image I/O and basic manipulations</li>
</ul>
<p><strong>For advanced deep learning:</strong></p>
<ul>
<li><strong>PyTorch</strong> and <strong>torchvision</strong> provide state-of-the-art pre-trained models</li>
<li><strong>TensorFlow/Keras</strong> offers alternative deep learning frameworks</li>
<li><strong>YOLO, RCNN, and Detectron2</strong> for object detection</li>
<li><strong>FaceNet, ArcFace</strong> for face recognition</li>
<li><strong>OpenPose, MediaPipe</strong> for pose estimation</li>
</ul>
<p><strong>For large-scale analysis:</strong></p>
<ul>
<li><strong>Dask</strong> for processing image collections larger than memory</li>
<li><strong>Ray</strong> for distributed computing across multiple machines</li>
<li><strong>Hugging Face Transformers</strong> for vision transformer models</li>
<li><strong>CLIP</strong> for text-image similarity</li>
</ul>
<p>The Python ecosystem provides unparalleled capabilities for image analysis that continue to evolve rapidly. Unlike the R version that required Python wrappers, Python offers direct access to cutting-edge computer vision research and production-ready tools.</p>
<p>For theoretical background, we recommend our <em>Distant Viewing</em> <span class="citation" data-cites="arnold2023distant">[<a href="#ref-arnold2023distant" role="doc-biblioref">1</a>]</span> text as well as Lev Manovich’s <em>Cultural Analytics</em> <span class="citation" data-cites="manovich2020cultural">[<a href="#ref-manovich2020cultural" role="doc-biblioref">3</a>]</span>. For technical deep learning background, see <em>Deep Learning</em> by Ian Goodfellow <span class="citation" data-cites="goodfellow2016deep">[<a href="#ref-goodfellow2016deep" role="doc-biblioref">4</a>]</span> and <em>Computer Vision: Algorithms and Applications</em> by Richard Szeliski <span class="citation" data-cites="szeliski2010computer">[<a href="#ref-szeliski2010computer" role="doc-biblioref">5</a>]</span>.</p>
<p>The combination of Python’s mature scientific computing ecosystem with rapidly advancing computer vision research makes it an ideal platform for computational analysis of visual culture, art history, media studies, and other image-rich humanities domains.</p>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-arnold2023distant" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Arnold, T and Tilton, L (2023 ). <em>Distant Viewing: Computational Exploration of Digital Images</em>. MIT Press</div>
</div>
<div id="ref-bermeitinger2019deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Bermeitinger, B, Gassner, S, Handschuh, S, Howanitz, G, Radisch, E and Rehbein, M (2019 ). Deep watching: Towards new methods of analyzing visual media in cultural studies. <em>Proceedings of ADHO DH Conference</em></div>
</div>
<div id="ref-manovich2020cultural" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Manovich, L (2020 ). <em>Cultural Analytics</em>. Mit Press</div>
</div>
<div id="ref-goodfellow2016deep" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Goodfellow, I, Bengio, Y, Courville, A and Bengio, Y (2016 ). <em>Deep Learning</em>. MIT press Cambridge</div>
</div>
<div id="ref-szeliski2010computer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Szeliski, R (2010 ). <em>Computer Vision: Algorithms and Applications</em>. Springer Nature</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/distant-viewing\.github\.io\/hdpy");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./09_spatial_data.html" class="pagination-link" aria-label="Spatial Data">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./11_audio_data.html" class="pagination-link" aria-label="Audio Data">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Audio Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Taylor Arnold and Lauren Tilton</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>A <a href="https://distantviewing.org/">Distant Viewing Lab</a> project</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>