<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Taylor Arnold and Lauren Tilton">

<title>6&nbsp; Textual Data – Humanities Data in Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./07_network_data.html" rel="next">
<link href="./05_collect.html" rel="prev">
<link href="./owl_explore.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7dd7401653f9b7f7a674e3bd3661a20e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_textual_data.html">Part II: Data Types</a></li><li class="breadcrumb-item"><a href="./06_textual_data.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Textual Data</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Humanities Data in Python</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/distant-viewing/hdpy" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Core</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_graphics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">EDA I: Visualizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_verbs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">EDA II: Organizing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_combine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">EDA III: Restructuring Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_collect.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Collecting Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Data Types</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_textual_data.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Textual Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_network_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Network Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_temporal_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Temporal Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_spatial_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_image_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Image Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_audio_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Audio Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_movingimage_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Moving Image Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_supervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Supervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_unsupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Unsupervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_deeplearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Transformers</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part IV: Programming</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_program.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_jsonxml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">JSON + XML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_databases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Databases</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">6.1</span> Introduction</a></li>
  <li><a href="#working-with-a-textual-corpus" id="toc-working-with-a-textual-corpus" class="nav-link" data-scroll-target="#working-with-a-textual-corpus"><span class="header-section-number">6.2</span> Working with a Textual Corpus</a></li>
  <li><a href="#nlp-pipeline" id="toc-nlp-pipeline" class="nav-link" data-scroll-target="#nlp-pipeline"><span class="header-section-number">6.3</span> NLP Pipeline</a></li>
  <li><a href="#tf-idf" id="toc-tf-idf" class="nav-link" data-scroll-target="#tf-idf"><span class="header-section-number">6.4</span> TF-IDF</a></li>
  <li><a href="#document-distance" id="toc-document-distance" class="nav-link" data-scroll-target="#document-distance"><span class="header-section-number">6.5</span> Document Distance</a></li>
  <li><a href="#dimensionality-reduction" id="toc-dimensionality-reduction" class="nav-link" data-scroll-target="#dimensionality-reduction"><span class="header-section-number">6.6</span> Dimensionality Reduction</a></li>
  <li><a href="#word-relationships" id="toc-word-relationships" class="nav-link" data-scroll-target="#word-relationships"><span class="header-section-number">6.7</span> Word Relationships</a></li>
  <li><a href="#texts-in-other-languages" id="toc-texts-in-other-languages" class="nav-link" data-scroll-target="#texts-in-other-languages"><span class="header-section-number">6.8</span> Texts in Other Languages</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions"><span class="header-section-number">6.9</span> Extensions</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_textual_data.html">Part II: Data Types</a></li><li class="breadcrumb-item"><a href="./06_textual_data.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Textual Data</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ch06" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Textual Data</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">6.1</span> Introduction</h2>
<p>In this chapter, a number of methods are introduced for working with textual data. By textual data, we have in mind the idea of a dataset where each observation consists of a piece of textual information. An observation could be as short as a single phrase or as long as a book-length document. In Python, textual data of this format can be stored as a string variable in a pandas DataFrame. No special format is needed to store and represent the starting data, in contrast to examples we will see in later chapters working with spatial and image data. However, while it is possible to get a textual dataset into a tabular format, often that is not the starting point for working with a collection texts. Typically, one might start with a directory full of text files, with one text in each file, or it might be necessary to build a dataset by iteratively calling an external resource. We will see a full example of the latter in Chap. 12. We will also assume that this conversion has already taken place.</p>
<p>The dataset that we will work with in this chapter is the collection of Wikipedia pages from 75 British authors that was briefly mentioned in Chap. 1. Wikipedia is a fun source because each page often has a lot of different kinds of data and spans across languages. At the same time, studying Wikipedia is a lens into what kinds of knowledge are prioritized and how ideas and concepts are framed. We will focus in this chapter on techniques for working with this collection to show summaries of each of the pages and find patterns and cluster of topics discussed across the collection. The techniques we introduce will be of general interest to anyone working with a collection of textual documents. For those interested in broader methodological debates, textual analysis has been theorized through concepts such as distant reading <span class="citation" data-cites="underwood2017genealogy">[<a href="#ref-underwood2017genealogy" role="doc-biblioref">1</a>]</span>, macroanalysis <span class="citation" data-cites="jockers2013macroanalysis">[<a href="#ref-jockers2013macroanalysis" role="doc-biblioref">2</a>]</span>, and cultural analytics <span class="citation" data-cites="manovich2020cultural">[<a href="#ref-manovich2020cultural" role="doc-biblioref">3</a>]</span>. At the end of chapter, we give references for other models that may be of interest in specific sub-domains as well as additional readings on methods.</p>
</section>
<section id="working-with-a-textual-corpus" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="working-with-a-textual-corpus"><span class="header-section-number">6.2</span> Working with a Textual Corpus</h2>
<p>We will start by loading the textual data as a tabular dataset into Python. There is one row for each document. Each row has a unique identifier called the <code>doc_id</code>, equal to the name of the page on Wikipedia, and a column called <code>text</code> that has all of the text from the page, with special HTML markup removed.</p>
<div id="8851f306" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> pd.read_csv(<span class="st">"data/wiki_uk_authors_text.csv"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>docs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Marie de France</td>
<td>Marie de France was a poet possibly born in wh...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Geoffrey Chaucer</td>
<td>Geoffrey Chaucer was an English poet author an...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>John Gower</td>
<td>John Gower was an English poet a contemporary ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>William Langland</td>
<td>William Langland is the presumed author of a w...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Margery Kempe</td>
<td>Margery Kempe was an English Christian mystic ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">70</td>
<td>Stephen Spender</td>
<td>Sir Stephen Harold Spender CBE was an English ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">71</td>
<td>Christopher Isherwood</td>
<td>Christopher William Bradshaw Isherwood was an ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">72</td>
<td>Edward Upward</td>
<td>Edward Falaise Upward FRSL was a British novel...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">73</td>
<td>Rex Warner</td>
<td>Rex Warner was an English classicist writer an...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">74</td>
<td>Seamus Heaney</td>
<td>Seamus Justin Heaney MRIA was an Irish poet pl...</td>
</tr>
</tbody>
</table>

<p>75 rows × 2 columns</p>
</div>
</div>
</div>
<p>In addition to the textual data itself, we have another table of metadata describing information about each of the authors in the collection. As shown in the code block below, we have the year of birth and year of death, a hand-constructed <code>era</code> flag indicating the time period the author was active, the <code>gender</code> of the author, a link to the Wikipedia URL, and an identifier called <code>short</code> that will be a useful short label when visualizing the data. We chose to include and use the term gender because of the historical power of the gender binary and to facilitate questions about gender in our dataset. For a great introduction to considerations about social category data, see D’Ignazio and Klein’s <em>Data Feminism</em>.</p>
<div id="bb4e331a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>meta <span class="op">=</span> pd.read_csv(<span class="st">"data/wiki_uk_meta.csv.gz"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>meta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th">born</th>
<th data-quarto-table-cell-role="th">died</th>
<th data-quarto-table-cell-role="th">era</th>
<th data-quarto-table-cell-role="th">gender</th>
<th data-quarto-table-cell-role="th">link</th>
<th data-quarto-table-cell-role="th">short</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Marie de France</td>
<td>1160</td>
<td>1215</td>
<td>Early</td>
<td>female</td>
<td>Marie_de_France</td>
<td>Marie d. F.</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Geoffrey Chaucer</td>
<td>1343</td>
<td>1400</td>
<td>Early</td>
<td>male</td>
<td>Geoffrey_Chaucer</td>
<td>Chaucer</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>John Gower</td>
<td>1330</td>
<td>1408</td>
<td>Early</td>
<td>male</td>
<td>John_Gower</td>
<td>Gower</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>William Langland</td>
<td>1332</td>
<td>1386</td>
<td>Early</td>
<td>male</td>
<td>William_Langland</td>
<td>Langland</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Margery Kempe</td>
<td>1373</td>
<td>1438</td>
<td>Early</td>
<td>female</td>
<td>Margery_Kempe</td>
<td>Kempe</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">70</td>
<td>Stephen Spender</td>
<td>1909</td>
<td>1995</td>
<td>Twentieth C</td>
<td>male</td>
<td>Stephen_Spender</td>
<td>Spender</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">71</td>
<td>Christopher Isherwood</td>
<td>1904</td>
<td>1986</td>
<td>Twentieth C</td>
<td>male</td>
<td>Christopher_Isherwood</td>
<td>Isherwood</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">72</td>
<td>Edward Upward</td>
<td>1903</td>
<td>2009</td>
<td>Twentieth C</td>
<td>male</td>
<td>Edward_Upward</td>
<td>Upward</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">73</td>
<td>Rex Warner</td>
<td>1905</td>
<td>1986</td>
<td>Twentieth C</td>
<td>male</td>
<td>Rex_Warner</td>
<td>Warner</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">74</td>
<td>Seamus Heaney</td>
<td>1939</td>
<td>1939</td>
<td>Twentieth C</td>
<td>male</td>
<td>Seamus_Heaney</td>
<td>Heaney</td>
</tr>
</tbody>
</table>

<p>75 rows × 7 columns</p>
</div>
</div>
</div>
<p>It would have been possible to include all of the metadata in the text dataset as well, since both have the same number of rows. We have decided to separate them into two for performance reasons, which can be particularly important depending on the computer one has access to. In our applications, we will frequently want to do a table join of the metadata into another large dataset. If the metadata contained a complete copy of each page, this could result in very large intermediate steps. We have avoided this problem by the way that our data are structured.</p>
<p>What can we do with these datasets using the methods introduced in previous chapters? The metadata is similar to the tables we have previously looked at; we could use pandas operations and visualization techniques to illustrate concepts such as when each author was alive and patterns of gender representation across the timeline of our collection. We could also use pandas merge operations from Chap. 4 to combine the two tables by the key <code>doc_id</code>. However, beyond this, there is not very much that we can do with the data in its current form. We need to do some processing of the textual data before we can work with it.</p>
</section>
<section id="nlp-pipeline" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="nlp-pipeline"><span class="header-section-number">6.3</span> NLP Pipeline</h2>
<p>Our input dataset is organized with one row for each Wikipedia page, which we will refer to as a <em>document</em>. The composition of a document will vary depending on the area of analysis. Each document might be a stanza, paragraph, page, chapter, book, and more. A standard first-step in text processing is to convert the document-level dataset into a token-level dataset, with one row for each word or punctuation mark (i.e., a token) in each document. The best and easiest way to convert a document-level dataset into a tokens-level dataset is to use a purpose-built algorithm called a <em>Natural Language Processing (NLP) Pipeline</em>. There are several packages in Python that allow us to apply natural language processing pipelines to our data. Here we will use the <strong>spaCy</strong> library, which provides fast and accurate linguistic annotation for a variety of different models and languages <span class="citation" data-cites="spacylib">[<a href="#ref-spacylib" role="doc-biblioref">4</a>]</span>. To start, we load the package and initialize the English language model:</p>
<div id="d6da34cf" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Load English language model</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If not installed: python -m spacy download en_core_web_sm</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once loaded, we can use spaCy to produce a token-level dataset from our <code>docs</code> input. The following function will process each document and extract token-level information:</p>
<div id="4a68c7f1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_documents(docs_df):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Process documents through spaCy NLP pipeline"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    tokens_list <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> docs_df.iterrows():</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        doc_id <span class="op">=</span> row[<span class="st">'doc_id'</span>]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> row[<span class="st">'text'</span>]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process text through spaCy</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        doc <span class="op">=</span> nlp(text)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        sent_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        token_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> sent <span class="kw">in</span> doc.sents:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            sent_id <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            token_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> token <span class="kw">in</span> sent:</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>                token_id <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>                tokens_list.append({</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'doc_id'</span>: doc_id,</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'sid'</span>: sent_id,</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'tid'</span>: token_id,</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'token'</span>: token.text,</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'token_with_ws'</span>: token.text_with_ws,</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'lemma'</span>: token.lemma_,</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'upos'</span>: token.pos_,</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'tag'</span>: token.tag_,</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'is_alpha'</span>: token.is_alpha,</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'is_stop'</span>: token.is_stop,</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'is_punct'</span>: token.is_punct,</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'dep'</span>: token.dep_,</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'head_idx'</span>: token.head.i <span class="cf">if</span> token.head <span class="op">!=</span> token <span class="cf">else</span> token.i</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(tokens_list)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Process a small sample first for demonstration</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>sample_docs <span class="op">=</span> docs.head(<span class="dv">3</span>)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>anno <span class="op">=</span> process_documents(sample_docs)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>anno</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th">sid</th>
<th data-quarto-table-cell-role="th">tid</th>
<th data-quarto-table-cell-role="th">token</th>
<th data-quarto-table-cell-role="th">token_with_ws</th>
<th data-quarto-table-cell-role="th">lemma</th>
<th data-quarto-table-cell-role="th">upos</th>
<th data-quarto-table-cell-role="th">tag</th>
<th data-quarto-table-cell-role="th">is_alpha</th>
<th data-quarto-table-cell-role="th">is_stop</th>
<th data-quarto-table-cell-role="th">is_punct</th>
<th data-quarto-table-cell-role="th">dep</th>
<th data-quarto-table-cell-role="th">head_idx</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Marie de France</td>
<td>1</td>
<td>1</td>
<td>Marie</td>
<td>Marie</td>
<td>Marie</td>
<td>PROPN</td>
<td>NNP</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>compound</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Marie de France</td>
<td>1</td>
<td>2</td>
<td>de</td>
<td>de</td>
<td>de</td>
<td>X</td>
<td>FW</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>nmod</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Marie de France</td>
<td>1</td>
<td>3</td>
<td>France</td>
<td>France</td>
<td>France</td>
<td>PROPN</td>
<td>NNP</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>nsubj</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Marie de France</td>
<td>1</td>
<td>4</td>
<td>was</td>
<td>was</td>
<td>be</td>
<td>AUX</td>
<td>VBD</td>
<td>True</td>
<td>True</td>
<td>False</td>
<td>ROOT</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Marie de France</td>
<td>1</td>
<td>5</td>
<td>a</td>
<td>a</td>
<td>a</td>
<td>DET</td>
<td>DT</td>
<td>True</td>
<td>True</td>
<td>False</td>
<td>det</td>
<td>5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10306</td>
<td>John Gower</td>
<td>72</td>
<td>2</td>
<td>D.S.</td>
<td>D.S.</td>
<td>D.S.</td>
<td>PROPN</td>
<td>NNP</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>compound</td>
<td>1541</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10307</td>
<td>John Gower</td>
<td>72</td>
<td>3</td>
<td>Brewer</td>
<td>Brewer</td>
<td>Brewer</td>
<td>PROPN</td>
<td>NNP</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>ROOT</td>
<td>1541</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10308</td>
<td>John Gower</td>
<td>72</td>
<td>4</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>PUNCT</td>
<td>.</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>punct</td>
<td>1541</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10309</td>
<td>John Gower</td>
<td>73</td>
<td>1</td>
<td>ISBN9781843845379</td>
<td>ISBN9781843845379</td>
<td>ISBN9781843845379</td>
<td>PROPN</td>
<td>NNP</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>ROOT</td>
<td>1543</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10310</td>
<td>John Gower</td>
<td>73</td>
<td>2</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>PUNCT</td>
<td>.</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>punct</td>
<td>1543</td>
</tr>
</tbody>
</table>

<p>10311 rows × 13 columns</p>
</div>
</div>
</div>
<p>There is a lot of information that has been automatically added to this table, thanks to the collective results of decades of research in computational linguistics and natural language processing. Each row corresponds to a word or a punctuation mark (created by the process of tokenization), along with metadata describing the token. Notice that reading down the column <code>token</code> reproduces the original text. The columns available are:</p>
<ul>
<li><strong>doc_id</strong>: A key that allows us to group tokens into documents and to link back into the original input table.</li>
<li><strong>sid</strong>: Numeric identifier of the sentence number.</li>
<li><strong>tid</strong>: Numeric identifier of the token within a sentence. The first three columns form a primary key for the table.</li>
<li><strong>token</strong>: A character variable containing the detected token, which is either a word or a punctuation mark.</li>
<li><strong>token_with_ws</strong>: The token with white space (i.e., spaces and new-line characters) added. This is useful if we wanted to re-create the original text from the token table.</li>
<li><strong>lemma</strong>: A normalized version of the token. For example, it removes start-of-sentence capitalization, turns all nouns into their singular form, and converts verbs into their infinitive form.</li>
<li><strong>upos</strong>: The universal part of speech code, which are parts of speech that can be defined in (most) spoken languages. These tend to correspond to the parts of speech taught in primary schools, such as “NOUN”, “ADJ” (Adjective), and “ADV” (Adverb).</li>
<li><strong>tag</strong>: A fine-grained part of speech code that depends on the specific language (here, English) and models being used.</li>
<li><strong>is_alpha</strong>, <strong>is_stop</strong>, <strong>is_punct</strong>: Boolean flags for alphabetic characters, stop words, and punctuation.</li>
<li><strong>dep</strong>: The dependency relation label.</li>
<li><strong>head_idx</strong>: The token index of the word in the sentence that this token is grammatically related to.</li>
</ul>
<p>There are many analyses that can be performed on the extracted features that are present in the <code>anno</code> table. Fortunately, many of these can be performed by directly using pandas operations covered in the first five chapters of this text, without the need for any new text-specific functions. For example, we can find the most common nouns in the dataset by filtering on the universal part of speech and grouping by lemma with the code below.</p>
<div id="6d287b6e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find most common nouns</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>common_nouns <span class="op">=</span> (anno</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"upos == 'NOUN'"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'lemma'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    .size()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    .reset_index(name<span class="op">=</span><span class="st">'count'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    .sort_values(<span class="st">'count'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">10</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>common_nouns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">lemma</th>
<th data-quarto-table-cell-role="th">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">790</td>
<td>work</td>
<td>49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">224</td>
<td>edition</td>
<td>29</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">724</td>
<td>time</td>
<td>29</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">118</td>
<td>century</td>
<td>25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">524</td>
<td>poet</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">794</td>
<td>year</td>
<td>20</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">403</td>
<td>life</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">125</td>
<td>chaucer</td>
<td>18</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">74</td>
<td>author</td>
<td>17</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">422</td>
<td>manuscript</td>
<td>16</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The most frequent nouns across the set of documents roughly fall into one of two categories. Those such as “year”, “life”, and “death”, and “family” are nouns that we would frequently associate with biographic entries for nearly any group of people. Others, such as “poem”, “book”, “poet”, and the somewhat more generic “work”, capture the specific objects that authors would produce and therefore would be prominent elements of their respective Wikipedia pages. The fact that these are two types of nouns that show up at the top of the list help to verify that both the dataset and the NLP pipeline are working as expected.</p>
<p>We can use a similar technique to learn about the contents of each of the 75 individual documents. Suppose we wanted to know which adjectives are most used on each page. This can be done by a sequence of pandas operations. First, we filter the data by the part of speech and group the rows of the dataset by the document id and lemma. Then, we count the number of rows for each unique combination of document and lemma and arrange the dataset in descending order of count. We can use the <code>head()</code> method on grouped data to take the most frequent adjectives within each document:</p>
<div id="bca800bc" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Top adjectives by document</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>top_adjectives <span class="op">=</span> (anno</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    .query(<span class="st">"upos == 'ADJ'"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    .groupby([<span class="st">'doc_id'</span>, <span class="st">'lemma'</span>])</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    .size()</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    .reset_index(name<span class="op">=</span><span class="st">'count'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    .sort_values([<span class="st">'doc_id'</span>, <span class="st">'count'</span>], ascending<span class="op">=</span>[<span class="va">True</span>, <span class="va">False</span>])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'doc_id'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">8</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    .groupby(<span class="st">'doc_id'</span>)[<span class="st">'lemma'</span>]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">'; '</span>.join(x))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    .reset_index()</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>top_adjectives</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th">lemma</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Geoffrey Chaucer</td>
<td>first; english; early; many; other; most; comm...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>John Gower</td>
<td>english; other; much; social; early; first; la...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Marie de France</td>
<td>such; new; first; late; many; 12th; adulterous...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The output shows many connections between adjectives and the authors. Here, the connections again fall roughly into two groups. Some of the adjectives are fairly generic—such as “more”, “other”, and “many”—and probably say more about the people writing the pages than the subjects of the pages themselves. Other adjectives provide more contextual information about each of the authors. For example, several selected adjectives are key descriptions of an author’s work, such as “Victorian” associated with certain authors and “Gothic” with others. While it is good to see expected relationships to demonstrate the data and techniques are functioning properly, it is also great when the computational techniques highlight the unexpected.</p>
</section>
<section id="tf-idf" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="tf-idf"><span class="header-section-number">6.4</span> TF-IDF</h2>
<p>In the previous section, we saw that counting the number of times each token or lemma occurs in a document is a useful way of quickly summarizing the content of a document. This approach can be improved by using a scaled version of the count metric. The issue with raw counts is that will tend to highlight very common words such as “the”, “have”, and “her”. These can be somewhat avoided by removing a pre-compiled set of known common words—often called <em>stopwords</em>—or by doing part of speech filtering. These coarse approaches, however, mostly just move the issue down to a slightly less set of words that also do not necessarily summarize the contents of each document very well. For example, “publisher” is a frequently used term in many of the documents in this collection due to the subject matter, but that does not mean that it is particularly informative since it occurs in almost every page.</p>
<p>A common alternative technique is to combine information about the frequency of a word within a document with the frequency of the term across the entire collection. We return here to the importance of how we define a document, which will shape our analysis. Metrics of this form are known as <em>term frequency–inverse document frequency scores</em> (TF-IDF). A common version of TF-IDF computes a score for every combination of term and document by dividing the logarithm of the number of times the term occurs with the logarithm of the number of documents that contain the term at least once. The logarithm is a function that is used to make sure that counts do not grow too fast. For example, a count of about 1000 is only approximately twice as big on the logarithmic scale as a count of 25, in comparison to being 40 times larger on a linear scale. Mathematically, we define this TF-IDF function using the following formula, where <em>tf</em> gives the term frequency and <em>df</em> gives the document frequency. The plus one in the equation avoids a division by zero.</p>
<p><span class="math display">\[ \text{tfidf} = \frac{log(\text{tf})}{log(\text{df + 1})} \]</span></p>
<p>This score gives a measurement of how important a term is in describing a document in the context of the other documents. If we select words with the highest TF-IDF score for each document, these should give a good measurement of what terms best describe each document uniquely from the rest of the collection. Note that while the scaling functions given above are popular choices, they are not universal. Other papers and software may make different choices with moderate effects on the output results.</p>
<p>We can compute TF-IDF scores using scikit-learn’s TfidfVectorizer:</p>
<div id="e69c7ef0" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare documents for TF-IDF</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># First, let's create document-level text by filtering and concatenating tokens</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_document_texts(anno_df, pos_filter<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Create document-level texts from token annotations"""</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pos_filter:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        filtered_anno <span class="op">=</span> anno_df.query(<span class="ss">f"upos in </span><span class="sc">{</span>pos_filter<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        filtered_anno <span class="op">=</span> anno_df</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    doc_texts <span class="op">=</span> (filtered_anno</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        .groupby(<span class="st">'doc_id'</span>)[<span class="st">'lemma'</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        .<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join(x))</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        .reset_index()</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc_texts</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create noun-only documents</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>noun_docs <span class="op">=</span> create_document_texts(anno, [<span class="st">'NOUN'</span>])</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply TF-IDF</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(min_df<span class="op">=</span><span class="fl">0.05</span>, lowercase<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>tfidf_matrix <span class="op">=</span> vectorizer.fit_transform(noun_docs[<span class="st">'lemma'</span>])</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame for easier manipulation</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>tfidf_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    tfidf_matrix.toarray(), </span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>feature_names,</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>noun_docs[<span class="st">'doc_id'</span>]</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Get top terms for each document</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_top_terms_per_doc(tfidf_df, n_terms<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Get top TF-IDF terms for each document"""</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc_id <span class="kw">in</span> tfidf_df.index:</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        top_terms <span class="op">=</span> (tfidf_df.loc[doc_id]</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>            .sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>            .head(n_terms)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">'doc_id'</span>: doc_id,</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">'top_terms'</span>: <span class="st">'; '</span>.join(top_terms.index)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>top_terms <span class="op">=</span> get_top_terms_per_doc(tfidf_df)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>top_terms</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th">top_terms</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Geoffrey Chaucer</td>
<td>edition; work; chaucer; time; text; century; y...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>John Gower</td>
<td>work; gower; poet; pound; praise; advice; line...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Marie de France</td>
<td>fable; woman; lover; husband; love; society; t...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can see that these words do not include many superfluous common words. If anything, they present too much interesting information, perhaps including many words that are only used once in a fairly oblique way within a text. As with the examples in the first section, we could clean this up with additional filtering. For example, filtering based on a minimum value of the term frequency would select the top terms. As a first pass, though, the results here already do a good job of summarizing the texts using a technique that we could use on nearly any collection of textual document. By summarizing, we can quickly get a sense of themes and topics, which becomes particularly powerful when comparing and contrasting texts.</p>
</section>
<section id="document-distance" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="document-distance"><span class="header-section-number">6.5</span> Document Distance</h2>
<p>Our approach so far has been to use the annotation table to summarize the content of each document. We now want to extend these techniques to find connections between and across different documents. In other words, we want to see how the Wikipedia pages relate to one another and see if there are structures that help us understand and visualize the entire dataset. In order to do these tasks, our approach will be to summarize each document as a set of numbers that capture different elements of each document. Any pair or set of pages that share similar summary numbers can be said to have, in some sense, shared similarities. To do this, we need to be able to think about each document as existing in a high-dimensional space. This can be a bit complex and intimidating on a first pass. Therefore, before showing the next topic, we will first walk through an example showing the concept of representing documents as sequences of numbers.</p>
<p>Consider the TF-IDF dataset that we produced in the previous section. The data format was a matrix with one row for each document and one column for every token. Let’s visualize this with just two terms to start:</p>
<div id="ec41305d" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a simple example with just two terms: "novel" and "poem"</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>simple_vectorizer <span class="op">=</span> TfidfVectorizer(vocabulary<span class="op">=</span>[<span class="st">'novel'</span>, <span class="st">'poem'</span>], lowercase<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to recreate our document texts to include these specific terms</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>all_docs <span class="op">=</span> create_document_texts(anno)  <span class="co"># All parts of speech</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>simple_tfidf <span class="op">=</span> simple_vectorizer.fit_transform(all_docs[<span class="st">'lemma'</span>])</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>simple_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    simple_tfidf.toarray(),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'novel'</span>, <span class="st">'poem'</span>],</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>all_docs[<span class="st">'doc_id'</span>]</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>simple_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">novel</th>
<th data-quarto-table-cell-role="th">poem</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Geoffrey Chaucer</td>
<td>0.249399</td>
<td>0.968401</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">John Gower</td>
<td>0.000000</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Marie de France</td>
<td>0.249399</td>
<td>0.968401</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The output now includes one row for each document and two columns with TF-IDF scores for “novel” and “poem”. We can then visualize what the output would look like with all the terms included. Using just these two columns, we can plot a set of pages with <code>novel</code> on the x-axis and <code>poem</code> on the y-axis. It will be useful to think of these as vectors starting at the origin, rather than points floating in space:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine <span class="im">import</span> <span class="op">*</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Select a subset of authors for visualization</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>selected_authors <span class="op">=</span> [</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Jane Austen"</span>, <span class="st">"Ann Radcliffe"</span>, <span class="st">"Rex Warner"</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"John Donne"</span>, <span class="st">"James Joyce"</span>, <span class="st">"Seamus Heaney"</span>, </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Lord Byron"</span>, <span class="st">"Samuel Beckett"</span>, <span class="st">"Oscar Wilde"</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> simple_df.loc[simple_df.index.isin(selected_authors)].reset_index()</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> (ggplot(plot_data, aes(x<span class="op">=</span><span class="st">'novel'</span>, y<span class="op">=</span><span class="st">'poem'</span>)) <span class="op">+</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>     geom_segment(aes(xend<span class="op">=</span><span class="dv">0</span>, yend<span class="op">=</span><span class="dv">0</span>), </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>                  arrow<span class="op">=</span><span class="bu">dict</span>(length<span class="op">=</span><span class="fl">0.3</span>), color<span class="op">=</span><span class="st">'black'</span>) <span class="op">+</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>     geom_text(aes(label<span class="op">=</span><span class="st">'doc_id'</span>), </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>               nudge_x<span class="op">=</span><span class="fl">0.01</span>, nudge_y<span class="op">=</span><span class="fl">0.01</span>, size<span class="op">=</span><span class="dv">8</span>) <span class="op">+</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>     labs(x<span class="op">=</span><span class="st">'Novel TF-IDF'</span>, y<span class="op">=</span><span class="st">'Poem TF-IDF'</span>) <span class="op">+</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>     theme_minimal())</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The take-away from our plot is that a matrix representation of the term frequency values provides an interesting way of grouping and exploring the relationships between documents. While we may not be able to directly visualize the same idea with more than two terms at the same time, we can consider abstractly thinking of each document living in a high dimensional space defined by the lemma counts and then looking at which documents are close to one another.</p>
<p>Let’s see how we can apply this technique to the entire dataset using all of the lemmas to show which documents are closest to one another. We can compute distances between documents using cosine similarity:</p>
<div id="cb00e82b" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity, cosine_distances</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute cosine distances (1 - cosine_similarity)</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>distance_matrix <span class="op">=</span> cosine_distances(tfidf_matrix)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame for easier manipulation</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>distance_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    distance_matrix,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>noun_docs[<span class="st">'doc_id'</span>],</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>noun_docs[<span class="st">'doc_id'</span>]</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Find closest document pairs</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_closest_pairs(distance_df):</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Find the closest document pairs"""</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    pairs <span class="op">=</span> []</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    docs <span class="op">=</span> distance_df.index</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, doc1 <span class="kw">in</span> <span class="bu">enumerate</span>(docs):</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, doc2 <span class="kw">in</span> <span class="bu">enumerate</span>(docs):</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&lt;</span> j:  <span class="co"># Avoid duplicates and self-pairs</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>                pairs.append({</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'document1'</span>: doc1,</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'document2'</span>: doc2,</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'distance'</span>: distance_df.loc[doc1, doc2]</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    pairs_df <span class="op">=</span> pd.DataFrame(pairs)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pairs_df.sort_values(<span class="st">'distance'</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>closest_pairs <span class="op">=</span> find_closest_pairs(distance_df)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>closest_pairs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">document1</th>
<th data-quarto-table-cell-role="th">document2</th>
<th data-quarto-table-cell-role="th">distance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Geoffrey Chaucer</td>
<td>John Gower</td>
<td>0.600292</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Geoffrey Chaucer</td>
<td>Marie de France</td>
<td>0.755999</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>John Gower</td>
<td>Marie de France</td>
<td>0.789774</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>These relationships seem much more as expected. The relationships include pairs of authors often associated with one another. For example, we might see links between authors from similar time periods or with similar themes. There are also connections between authors who worked in similar genres or shared cultural contexts.</p>
</section>
<section id="dimensionality-reduction" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="dimensionality-reduction"><span class="header-section-number">6.6</span> Dimensionality Reduction</h2>
<p>We need a strategy for visualizing the complex relationships between documents that are to be found in the high dimensions of the TF-IDF scores. We can do this through a strategy called dimensionality reduction. To put it another way, this is an approach to summarizing relationships between objects that are represented in high dimensions with a representation in a much lower space. We want to take representations of objects that consist of a large set of numbers and approximate them with a much smaller set of numbers. There are many motivations and applications for the application of dimensionality reduction to tasks in fields such as statistics, computer science, information science, and mathematics. Here, for our application, the main motivation is that if we can approximate the relationships between the large set of TF-IDF values by associating each document with a pair of numbers and then we could plot those numbers to recover the kind of visualization we started with in the previous section.</p>
<p>Our first approach involves the use of a technique called <em>principal component analysis</em> (PCA). PCA comes directly from noticing that our ultimate use of the high-dimensional structure in the previous section was to compute the distance between pairs of documents. The general goal of PCA can be viewed as generating a new representation of a high-dimensional dataset in a way that distances in the new space approximate those in the larger space. We can generate the PCA dimensions using scikit-learn’s PCA implementation:</p>
<div id="55df0d8b" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA to reduce to 2 components</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>pca_result <span class="op">=</span> pca.fit_transform(tfidf_matrix.toarray())</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame with results</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>pca_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    pca_result,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>],</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>noun_docs[<span class="st">'doc_id'</span>]</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge with metadata for visualization</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>pca_with_meta <span class="op">=</span> pca_df.merge(meta, on<span class="op">=</span><span class="st">'doc_id'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Explained variance ratio: </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>pca_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Explained variance ratio: [0.58157065 0.41842935]</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">doc_id</th>
<th data-quarto-table-cell-role="th">PC1</th>
<th data-quarto-table-cell-role="th">PC2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Geoffrey Chaucer</td>
<td>-0.317004</td>
<td>0.571663</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>John Gower</td>
<td>-0.425159</td>
<td>-0.518697</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Marie de France</td>
<td>0.742164</td>
<td>-0.052966</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The output already highlights one of the challenges of dimensionality reduction. Each of the components <code>PC1</code> and <code>PC2</code> is computed as a weighted sum of the TF-IDF scores across all of the lemmas. While some limited interpretation of the components is possible, it is difficult to fully understand exactly what is captured in each component. Instead, our goal will be to use these numbers in a plot that should provide insight into the data by showing which documents end up in similar parts of the plot:</p>
<div id="aaef3ce3" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PCA visualization</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample some authors for cleaner visualization</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>sample_authors <span class="op">=</span> pca_with_meta.sample(n<span class="op">=</span><span class="bu">min</span>(<span class="dv">40</span>, <span class="bu">len</span>(pca_with_meta)))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> (ggplot(sample_authors, aes(x<span class="op">=</span><span class="st">'PC1'</span>, y<span class="op">=</span><span class="st">'PC2'</span>, color<span class="op">=</span><span class="st">'era'</span>)) <span class="op">+</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>     geom_point(size<span class="op">=</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>     geom_text(aes(label<span class="op">=</span><span class="st">'doc_id'</span>), size<span class="op">=</span><span class="dv">6</span>, nudge_y<span class="op">=</span><span class="fl">0.1</span>, show_legend<span class="op">=</span><span class="va">False</span>) <span class="op">+</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>     labs(title<span class="op">=</span><span class="st">"PCA of British Authors Wikipedia Collection"</span>,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>          x<span class="op">=</span><span class="st">"First Principal Component"</span>,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>          y<span class="op">=</span><span class="st">"Second Principal Component"</span>,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>          color<span class="op">=</span><span class="st">"Era"</span>) <span class="op">+</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>     theme_minimal() <span class="op">+</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>     theme(axis_text<span class="op">=</span>element_blank(),</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>           axis_ticks<span class="op">=</span>element_blank()))</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="06_textual_data_files/figure-html/cell-13-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="06_textual_data_files/figure-html/cell-13-output-1.png" width="672" height="480" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The output of the plot immediately provides a richer view of the intricate relationships between the different authors than we get directly looking at the pairs of closest documents. This is not because the individual links lack interesting relationships, but rather that they require additional work to make the patterns visible. We can see clustering patterns that reflect temporal and thematic similarities between authors.</p>
<p>There are many other techniques for dimensionality reduction beyond PCA. Another popular method for reducing the dimension of our dataset is the <em>Uniform Manifold Approximation and Projection</em> (UMAP). As with PCA, the UMAP method tries to retain information about distances between pairs of documents. However, whereas PCA focuses on all distances between documents, UMAP only focuses on keeping observations close in the new space that were also close together in the original space:</p>
<div id="b204ebfb" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: UMAP requires specific Python version compatibility</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># For demonstration, we'll use PCA as an alternative dimensionality reduction method</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># To use UMAP, install with: pip install umap-learn</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and replace this section with:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># import umap</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># umap_reducer = umap.UMAP(n_components=2, n_neighbors=5, random_state=42)</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># umap_result = umap_reducer.fit_transform(tfidf_matrix.toarray())</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach using PCA for similar visualization</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA as UMAP alternative (for demonstration)</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>pca_reducer <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>umap_result <span class="op">=</span> pca_reducer.fit_transform(tfidf_matrix.toarray())</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataFrame with results</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>umap_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    umap_result,</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'UMAP1'</span>, <span class="st">'UMAP2'</span>],</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>noun_docs[<span class="st">'doc_id'</span>]</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge with metadata</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>umap_with_meta <span class="op">=</span> umap_df.merge(meta, on<span class="op">=</span><span class="st">'doc_id'</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample for visualization</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>sample_authors_umap <span class="op">=</span> umap_with_meta.sample(n<span class="op">=</span><span class="bu">min</span>(<span class="dv">40</span>, <span class="bu">len</span>(umap_with_meta)))</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>p_umap <span class="op">=</span> (ggplot(sample_authors_umap, aes(x<span class="op">=</span><span class="st">'UMAP1'</span>, y<span class="op">=</span><span class="st">'UMAP2'</span>, color<span class="op">=</span><span class="st">'era'</span>)) <span class="op">+</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>          geom_point(size<span class="op">=</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>          geom_text(aes(label<span class="op">=</span><span class="st">'doc_id'</span>), size<span class="op">=</span><span class="dv">6</span>, nudge_y<span class="op">=</span><span class="fl">0.1</span>, show_legend<span class="op">=</span><span class="va">False</span>) <span class="op">+</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>          labs(title<span class="op">=</span><span class="st">"UMAP-style Visualization of British Authors Wikipedia Collection"</span>,</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>               subtitle<span class="op">=</span><span class="st">"(Using PCA for demonstration - replace with UMAP when available)"</span>,</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>               x<span class="op">=</span><span class="st">"Dimension 1"</span>,</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>               y<span class="op">=</span><span class="st">"Dimension 2"</span>,</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>               color<span class="op">=</span><span class="st">"Era"</span>) <span class="op">+</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>          theme_minimal() <span class="op">+</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>          theme(axis_text<span class="op">=</span>element_blank(),</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>                axis_ticks<span class="op">=</span>element_blank()))</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>p_umap</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="06_textual_data_files/figure-html/cell-14-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="06_textual_data_files/figure-html/cell-14-output-1.png" width="672" height="480" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The output of the UMAP plot shows different clustering patterns compared to PCA. As with the principal components, the exact values of the dimensions are unimportant here. The relationships between the documents are what we are interested in. The points are typically more uniformly spread through the plot than the PCA visualization. This has the benefit of making it easier to read but may obscure some hierarchical relationships. The benefits of UMAP become more apparent with larger datasets; we will see an example of this technique again using a much larger set of observations in Chap. 10 when we apply it to image data.</p>
</section>
<section id="word-relationships" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="word-relationships"><span class="header-section-number">6.7</span> Word Relationships</h2>
<p>In the previous two sections, we have focused on using word counts to describe documents. We can also analyze relationships between words by examining which words tend to appear in similar documents. Using the transpose of our TF-IDF matrix, we can reapply the techniques we have already seen to show relationships between words:</p>
<div id="4bf48e62" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transpose the TF-IDF matrix to analyze word relationships</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Limit to most frequent words for computational efficiency</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>word_tfidf <span class="op">=</span> tfidf_df.T  <span class="co"># Transpose so words are rows, documents are columns</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute cosine similarity between words</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>word_similarity <span class="op">=</span> cosine_similarity(word_tfidf)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>word_distance <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> word_similarity</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create word distance DataFrame</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>word_dist_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    word_distance,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>word_tfidf.index,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>word_tfidf.index</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Find closest word pairs</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_closest_word_pairs(distance_df, n_pairs<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Find the closest word pairs"""</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    pairs <span class="op">=</span> []</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> distance_df.index</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, word1 <span class="kw">in</span> <span class="bu">enumerate</span>(words):</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, word2 <span class="kw">in</span> <span class="bu">enumerate</span>(words):</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&lt;</span> j:  <span class="co"># Avoid duplicates and self-pairs</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>                pairs.append({</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'word1'</span>: word1,</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'word2'</span>: word2,</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'distance'</span>: distance_df.loc[word1, word2]</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    pairs_df <span class="op">=</span> pd.DataFrame(pairs)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pairs_df.sort_values(<span class="st">'distance'</span>).head(n_pairs)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>closest_word_pairs <span class="op">=</span> find_closest_word_pairs(word_dist_df)</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>closest_word_pairs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">word1</th>
<th data-quarto-table-cell-role="th">word2</th>
<th data-quarto-table-cell-role="th">distance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">43249</td>
<td>aspect</td>
<td>process</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43036</td>
<td>aspect</td>
<td>imprisonment</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42941</td>
<td>aspect</td>
<td>era</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">49093</td>
<td>attention</td>
<td>process</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42810</td>
<td>aspect</td>
<td>cause</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">162355</td>
<td>era</td>
<td>imprisonment</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">48880</td>
<td>attention</td>
<td>imprisonment</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">162568</td>
<td>era</td>
<td>process</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">82188</td>
<td>cause</td>
<td>rest</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">210217</td>
<td>imprisonment</td>
<td>rest</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">162622</td>
<td>era</td>
<td>rest</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">49147</td>
<td>attention</td>
<td>rest</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">210163</td>
<td>imprisonment</td>
<td>process</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">81921</td>
<td>cause</td>
<td>imprisonment</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">48654</td>
<td>attention</td>
<td>cause</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">284128</td>
<td>process</td>
<td>rest</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">48785</td>
<td>attention</td>
<td>era</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43303</td>
<td>aspect</td>
<td>rest</td>
<td>-4.440892e-16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">82134</td>
<td>cause</td>
<td>process</td>
<td>-4.440892e-16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">42763</td>
<td>aspect</td>
<td>attention</td>
<td>-4.440892e-16</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As with the document pairs, the output shows pairs of words that show different kinds of thematic similarity. Some are closely related semantic pairs such as “play” and “playwright” or “poet” and “poetry”. Others illustrate larger themes that are covered in some, though not all, of the Wikipedia pages. These include pairs for more research-oriented sections and pairs for biographical information.</p>
<p>We can also visualize word relationships using PCA:</p>
<div id="b67429f4" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA to word relationships (using top 50 words for readability)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>top_words <span class="op">=</span> word_tfidf.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).nlargest(<span class="dv">50</span>).index</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>word_subset <span class="op">=</span> word_tfidf.loc[top_words]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>word_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>word_pca_result <span class="op">=</span> word_pca.fit_transform(word_subset)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>word_pca_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    word_pca_result,</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'PC1'</span>, <span class="st">'PC2'</span>],</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>word_subset.index</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>p_words <span class="op">=</span> (ggplot(word_pca_df, aes(x<span class="op">=</span><span class="st">'PC1'</span>, y<span class="op">=</span><span class="st">'PC2'</span>)) <span class="op">+</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>           geom_text(aes(label<span class="op">=</span><span class="st">'index'</span>), size<span class="op">=</span><span class="dv">8</span>) <span class="op">+</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>           labs(title<span class="op">=</span><span class="st">"PCA of Word Relationships"</span>,</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>                x<span class="op">=</span><span class="st">"First Principal Component"</span>,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>                y<span class="op">=</span><span class="st">"Second Principal Component"</span>) <span class="op">+</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>           theme_minimal() <span class="op">+</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>           theme(axis_text<span class="op">=</span>element_blank(),</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                 axis_ticks<span class="op">=</span>element_blank()))</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>p_words</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="06_textual_data_files/figure-html/cell-16-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="06_textual_data_files/figure-html/cell-16-output-1.png" width="672" height="480" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The plot does a great job of clustering the words into different sections based on their themes. We can see groupings of words related to poetry, book production, family relations, and scholarly terms.</p>
</section>
<section id="texts-in-other-languages" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="texts-in-other-languages"><span class="header-section-number">6.8</span> Texts in Other Languages</h2>
<p>One of the reasons that we enjoy using the content of Wikipedia pages as example datasets for textual analysis is that it is possible to get the page text in a large number of different languages. One of the most interesting aspects of textual analysis is that we can apply our techniques to study how differences across languages and cultures affect the way that knowledge is created and distributed.</p>
<p>Let’s see how our text analysis pipeline can be modified to work with Wikipedia pages from the French version of the site. SpaCy provides models for many different languages:</p>
<div id="ddc534dc" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>nlp_fr <span class="op">=</span> spacy.load(<span class="st">"fr_core_news_sm"</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Read French Wikipedia data</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>docs_fr <span class="op">=</span> pd.read_csv(<span class="st">"data/wiki_uk_authors_text_fr.csv"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"French documents shape: </span><span class="sc">{</span>docs_fr<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Process French documents (sample for demonstration)</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>sample_fr <span class="op">=</span> docs_fr.head(<span class="dv">3</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_french_documents(docs_df, nlp_model):</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Process French documents through spaCy NLP pipeline"""</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    tokens_list <span class="op">=</span> []</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> docs_df.iterrows():</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        doc_id <span class="op">=</span> row[<span class="st">'doc_id'</span>]</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> row[<span class="st">'text'</span>]</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process text through French spaCy model</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        doc <span class="op">=</span> nlp_model(text)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        sent_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        token_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> sent <span class="kw">in</span> doc.sents:</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>            sent_id <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>            token_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> token <span class="kw">in</span> sent:</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>                token_id <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>                tokens_list.append({</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'doc_id'</span>: doc_id,</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'sid'</span>: sent_id,</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'tid'</span>: token_id,</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'token'</span>: token.text,</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'lemma'</span>: token.lemma_,</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'upos'</span>: token.pos_,</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'is_alpha'</span>: token.is_alpha,</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'is_stop'</span>: token.is_stop</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(tokens_list)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>anno_fr <span class="op">=</span> process_french_documents(sample_fr, nlp_fr)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"French annotations sample:"</span>)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anno_fr.head(<span class="dv">12</span>))</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze French TF-IDF</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>fr_noun_docs <span class="op">=</span> create_document_texts(anno_fr.query(<span class="st">"upos == 'NOUN'"</span>))</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>fr_vectorizer <span class="op">=</span> TfidfVectorizer(min_df<span class="op">=</span><span class="fl">0.1</span>, lowercase<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>fr_tfidf_matrix <span class="op">=</span> fr_vectorizer.fit_transform(fr_noun_docs[<span class="st">'lemma'</span>])</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>fr_tfidf_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>    fr_tfidf_matrix.toarray(),</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>fr_vectorizer.get_feature_names_out(),</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>fr_noun_docs[<span class="st">'doc_id'</span>]</span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>fr_top_terms <span class="op">=</span> get_top_terms_per_doc(fr_tfidf_df)</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top French terms by document:"</span>)</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(fr_top_terms)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>French documents shape: (73, 2)
French annotations sample:
             doc_id  sid  tid        token        lemma   upos  is_alpha  \
0   Marie de France    1    1        Marie        marie   NOUN      True   
1   Marie de France    1    2           de           de    ADP      True   
2   Marie de France    1    3       France       France  PROPN      True   
3   Marie de France    1    4          est         être    AUX      True   
4   Marie de France    1    5          une           un    DET      True   
5   Marie de France    1    6     poétesse     poétesse   NOUN      True   
6   Marie de France    1    7           de           de    ADP      True   
7   Marie de France    1    8           la           le    DET      True   
8   Marie de France    1    9  Renaissance  Renaissance  PROPN      True   
9   Marie de France    1   10           du           de    ADP      True   
10  Marie de France    1   11   XIIesiècle   XIIesiècle    NUM      True   
11  Marie de France    1   12           la           le    DET      True   

    is_stop  
0     False  
1      True  
2     False  
3      True  
4      True  
5     False  
6      True  
7      True  
8     False  
9      True  
10    False  
11     True  
Top French terms by document:
             doc_id                                          top_terms
0  Geoffrey Chaucer  roi; duc; fille; fils; document; période; anné...
1        John Gower  œuvre; référence; source; mirour; révolte; con...
2   Marie de France  marie; fable; lai; manuscrit; cour; conte; lan...</code></pre>
</div>
</div>
<p>By design, the output of the annotations have the same general structure as the annotations from the English data. The values in the <code>upos</code> columns are consistent across languages. Language-specific information is captured in the token-level features. We can see that the lemmatization process has taken account of specific aspects of French grammar.</p>
<p>The output from the French model shows many tokens that describe the areas of literature, themes, and key characteristics for each author. There are also interesting comparisons to be made to the English pages. A systematic study of differences between the Wikipedia pages in different languages can help understand differences in the perception of these authors across linguistic worlds.</p>
</section>
<section id="extensions" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="extensions"><span class="header-section-number">6.9</span> Extensions</h2>
<p>We started this chapter with the annotation of textual data using an NLP pipeline. We did not touch on the underlying algorithms and theory for how each step in the pipeline is actually being handled. For this, the standard reference is Jurafsky and Martin’s <em>Speech and Language Processing</em> <span class="citation" data-cites="jurafsky2000computational">[<a href="#ref-jurafsky2000computational" role="doc-biblioref">5</a>]</span>. The text is thorough and quite dense, but requires little in the way of prerequisites and is very accessible.</p>
<p>Using the annotations, we briefly looked at several different methods for understanding a corpus of text. There are also many other examples of tasks in text analysis, several of which are popular in humanities applications. Examples include sentiment analysis <span class="citation" data-cites="pang2008opinion">[<a href="#ref-pang2008opinion" role="doc-biblioref">6</a>]</span>, concept mining <span class="citation" data-cites="kolekar2009semantic">[<a href="#ref-kolekar2009semantic" role="doc-biblioref">7</a>]</span>, and spectral clustering <span class="citation" data-cites="von2007tutorial">[<a href="#ref-von2007tutorial" role="doc-biblioref">8</a>]</span>.</p>
<p>Another commonly used text analysis technique in the humanities are topic models. These techniques, such as Latent Dirichlet Allocation (LDA), can be implemented in Python using libraries like <code>gensim</code> or <code>scikit-learn</code>. A good introduction to topic modeling concepts is given by Blei <span class="citation" data-cites="blei2003latent">[<a href="#ref-blei2003latent" role="doc-biblioref">9</a>]</span>. The mathematical details require understanding of Bayesian statistics and variational inference.</p>
<p>For more advanced text analysis in Python, consider exploring: - <strong>Transformers</strong> and <strong>BERT</strong> models via the <code>transformers</code> library - <strong>Word embeddings</strong> using <code>gensim</code> or <code>word2vec</code> - <strong>Named entity recognition</strong> and <strong>coreference resolution</strong> via spaCy - <strong>Sentiment analysis</strong> using <code>vaderSentiment</code> or transformer models - <strong>Topic modeling</strong> with <code>gensim</code> or <code>scikit-learn</code></p>
<p>The Python ecosystem provides rich tools for text analysis that continue to evolve rapidly, particularly in the area of large language models and transformer architectures.</p>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-underwood2017genealogy" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Underwood, T (2017 ). A genealogy of distant reading. <em>DHQ: Digital Humanities Quarterly</em>. <strong>11</strong></div>
</div>
<div id="ref-jockers2013macroanalysis" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Jockers, M L (2013 ). <em>Macroanalysis: Digital Methods and Literary History</em>. University of Illinois Press</div>
</div>
<div id="ref-manovich2020cultural" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Manovich, L (2020 ). <em>Cultural Analytics</em>. Mit Press</div>
</div>
<div id="ref-spacylib" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Vasiliev, Y (2020 ). <em>Natural Language Processing with Python and spaCy: A Practical Introduction</em>. No Starch Press</div>
</div>
<div id="ref-jurafsky2000computational" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Jurafsky, D and Martin, J (2000 ). Computational linguistics and speech recognition, 2000. Prentice Hall</div>
</div>
<div id="ref-pang2008opinion" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Pang, B, Lee, L and others (2008 ). Opinion mining and sentiment analysis. <em>Foundations and Trends<span></span> in information retrieval</em>. Now Publishers, Inc. <strong>2</strong> 1–135</div>
</div>
<div id="ref-kolekar2009semantic" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Kolekar, M H, Palaniappan, K, Sengupta, S and Seetharaman, G (2009 ). Semantic concept mining based on hierarchical event detection for soccer video indexing. <em>Journal of multimedia</em>. NIH Public Access. <strong>4</strong> 298</div>
</div>
<div id="ref-von2007tutorial" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Von Luxburg, U (2007 ). A tutorial on spectral clustering. <em>Statistics and computing</em>. Springer. <strong>17</strong> 395–416</div>
</div>
<div id="ref-blei2003latent" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Blei, D M, Ng, A Y and Jordan, M I (2003 ). Latent dirichlet allocation. <em>Journal of machine Learning research</em>. <strong>3</strong> 993–1022</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/distant-viewing\.github\.io\/hdpy");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05_collect.html" class="pagination-link" aria-label="Collecting Data">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Collecting Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./07_network_data.html" class="pagination-link" aria-label="Network Data">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Network Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Taylor Arnold and Lauren Tilton</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>A <a href="https://distantviewing.org/">Distant Viewing Lab</a> project</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>